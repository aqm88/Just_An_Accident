{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8c0174-265e-41fc-aad6-5d02cea1eb7e",
   "metadata": {},
   "source": [
    "The first thing we need to do is import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f0f128-5604-4e44-b524-dd546cf9f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\brook\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\brook\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\brook\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\brook\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brook\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a4d2d-a8c5-41db-ad24-53bcd4265cc1",
   "metadata": {},
   "source": [
    "Then we load the data and do some basic exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f716bd-f258-4ba9-8f77-88e165815d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (595212, 59)\n",
      "Test Shape: (892816, 58)\n",
      "Train Data:\n",
      "    id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
      "0   7       0          2              2          5              1   \n",
      "1   9       0          1              1          7              0   \n",
      "2  13       0          5              4          9              1   \n",
      "3  16       0          0              1          2              0   \n",
      "4  17       0          0              2          0              1   \n",
      "\n",
      "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
      "0              0              0              1              0  ...   \n",
      "1              0              0              0              1  ...   \n",
      "2              0              0              0              1  ...   \n",
      "3              0              1              0              0  ...   \n",
      "4              0              1              0              0  ...   \n",
      "\n",
      "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
      "0           9           1           5           8               0   \n",
      "1           3           1           1           9               0   \n",
      "2           4           2           7           7               0   \n",
      "3           2           2           4           9               0   \n",
      "4           3           1           1           3               0   \n",
      "\n",
      "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
      "0               1               1               0               0   \n",
      "1               1               1               0               1   \n",
      "2               1               1               0               1   \n",
      "3               0               0               0               0   \n",
      "4               0               0               1               1   \n",
      "\n",
      "   ps_calc_20_bin  \n",
      "0               1  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "\n",
      "[5 rows x 59 columns]\n",
      "Test Data:\n",
      "    id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
      "0   0          0              1          8              1              0   \n",
      "1   1          4              2          5              1              0   \n",
      "2   2          5              1          3              0              0   \n",
      "3   3          0              1          6              0              0   \n",
      "4   4          5              1          7              0              0   \n",
      "\n",
      "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
      "0              0              1              0              0  ...   \n",
      "1              0              0              0              1  ...   \n",
      "2              0              0              0              1  ...   \n",
      "3              1              0              0              0  ...   \n",
      "4              0              0              0              1  ...   \n",
      "\n",
      "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
      "0           1           1           1          12               0   \n",
      "1           2           0           3          10               0   \n",
      "2           4           0           2           4               0   \n",
      "3           5           1           0           5               1   \n",
      "4           4           0           0           4               0   \n",
      "\n",
      "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
      "0               1               1               0               0   \n",
      "1               0               1               1               0   \n",
      "2               0               0               0               0   \n",
      "3               0               1               0               0   \n",
      "4               1               1               0               0   \n",
      "\n",
      "   ps_calc_20_bin  \n",
      "0               1  \n",
      "1               1  \n",
      "2               0  \n",
      "3               0  \n",
      "4               1  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "Train Data Description:\n",
      "                  id         target      ps_ind_01  ps_ind_02_cat  \\\n",
      "count  5.952120e+05  595212.000000  595212.000000  595212.000000   \n",
      "mean   7.438036e+05       0.036448       1.900378       1.358943   \n",
      "std    4.293678e+05       0.187401       1.983789       0.664594   \n",
      "min    7.000000e+00       0.000000       0.000000      -1.000000   \n",
      "25%    3.719915e+05       0.000000       0.000000       1.000000   \n",
      "50%    7.435475e+05       0.000000       1.000000       1.000000   \n",
      "75%    1.115549e+06       0.000000       3.000000       2.000000   \n",
      "max    1.488027e+06       1.000000       7.000000       4.000000   \n",
      "\n",
      "           ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  \\\n",
      "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
      "mean        4.423318       0.416794       0.405188       0.393742   \n",
      "std         2.699902       0.493311       1.350642       0.488579   \n",
      "min         0.000000      -1.000000      -1.000000       0.000000   \n",
      "25%         2.000000       0.000000       0.000000       0.000000   \n",
      "50%         4.000000       0.000000       0.000000       0.000000   \n",
      "75%         6.000000       1.000000       0.000000       1.000000   \n",
      "max        11.000000       1.000000       6.000000       1.000000   \n",
      "\n",
      "       ps_ind_07_bin  ps_ind_08_bin  ...     ps_calc_11     ps_calc_12  \\\n",
      "count  595212.000000  595212.000000  ...  595212.000000  595212.000000   \n",
      "mean        0.257033       0.163921  ...       5.441382       1.441918   \n",
      "std         0.436998       0.370205  ...       2.332871       1.202963   \n",
      "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
      "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
      "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
      "75%         1.000000       0.000000  ...       7.000000       2.000000   \n",
      "max         1.000000       1.000000  ...      19.000000      10.000000   \n",
      "\n",
      "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
      "count  595212.000000  595212.000000   595212.000000   595212.000000   \n",
      "mean        2.872288       7.539026        0.122427        0.627840   \n",
      "std         1.694887       2.746652        0.327779        0.483381   \n",
      "min         0.000000       0.000000        0.000000        0.000000   \n",
      "25%         2.000000       6.000000        0.000000        0.000000   \n",
      "50%         3.000000       7.000000        0.000000        1.000000   \n",
      "75%         4.000000       9.000000        0.000000        1.000000   \n",
      "max        13.000000      23.000000        1.000000        1.000000   \n",
      "\n",
      "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
      "count   595212.000000   595212.000000   595212.000000   595212.000000  \n",
      "mean         0.554182        0.287182        0.349024        0.153318  \n",
      "std          0.497056        0.452447        0.476662        0.360295  \n",
      "min          0.000000        0.000000        0.000000        0.000000  \n",
      "25%          0.000000        0.000000        0.000000        0.000000  \n",
      "50%          1.000000        0.000000        0.000000        0.000000  \n",
      "75%          1.000000        1.000000        1.000000        0.000000  \n",
      "max          1.000000        1.000000        1.000000        1.000000  \n",
      "\n",
      "[8 rows x 59 columns]\n",
      "Test Data Description:\n",
      "                  id      ps_ind_01  ps_ind_02_cat      ps_ind_03  \\\n",
      "count  8.928160e+05  892816.000000  892816.000000  892816.000000   \n",
      "mean   7.441535e+05       1.902371       1.358613       4.413734   \n",
      "std    4.296830e+05       1.986503       0.663002       2.700149   \n",
      "min    0.000000e+00       0.000000      -1.000000       0.000000   \n",
      "25%    3.720218e+05       0.000000       1.000000       2.000000   \n",
      "50%    7.443070e+05       1.000000       1.000000       4.000000   \n",
      "75%    1.116308e+06       3.000000       2.000000       6.000000   \n",
      "max    1.488026e+06       7.000000       4.000000      11.000000   \n",
      "\n",
      "       ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  \\\n",
      "count  892816.000000  892816.000000  892816.000000  892816.000000   \n",
      "mean        0.417361       0.408132       0.393246       0.257191   \n",
      "std         0.493453       1.355068       0.488471       0.437086   \n",
      "min        -1.000000      -1.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         1.000000       0.000000       1.000000       1.000000   \n",
      "max         1.000000       6.000000       1.000000       1.000000   \n",
      "\n",
      "       ps_ind_08_bin  ps_ind_09_bin  ...     ps_calc_11     ps_calc_12  \\\n",
      "count  892816.000000  892816.000000  ...  892816.000000  892816.000000   \n",
      "mean        0.163659       0.185905  ...       5.438478       1.440265   \n",
      "std         0.369966       0.389030  ...       2.330081       1.200620   \n",
      "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
      "25%         0.000000       0.000000  ...       4.000000       1.000000   \n",
      "50%         0.000000       0.000000  ...       5.000000       1.000000   \n",
      "75%         0.000000       0.000000  ...       7.000000       2.000000   \n",
      "max         1.000000       1.000000  ...      20.000000      11.000000   \n",
      "\n",
      "          ps_calc_13     ps_calc_14  ps_calc_15_bin  ps_calc_16_bin  \\\n",
      "count  892816.000000  892816.000000   892816.000000   892816.000000   \n",
      "mean        2.875013       7.540367        0.123720        0.627756   \n",
      "std         1.694072       2.745882        0.329262        0.483403   \n",
      "min         0.000000       0.000000        0.000000        0.000000   \n",
      "25%         2.000000       6.000000        0.000000        0.000000   \n",
      "50%         3.000000       7.000000        0.000000        1.000000   \n",
      "75%         4.000000       9.000000        0.000000        1.000000   \n",
      "max        15.000000      28.000000        1.000000        1.000000   \n",
      "\n",
      "       ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  ps_calc_20_bin  \n",
      "count   892816.000000   892816.000000   892816.000000   892816.000000  \n",
      "mean         0.554660        0.287796        0.349344        0.152428  \n",
      "std          0.497004        0.452736        0.476763        0.359435  \n",
      "min          0.000000        0.000000        0.000000        0.000000  \n",
      "25%          0.000000        0.000000        0.000000        0.000000  \n",
      "50%          1.000000        0.000000        0.000000        0.000000  \n",
      "75%          1.000000        1.000000        1.000000        0.000000  \n",
      "max          1.000000        1.000000        1.000000        1.000000  \n",
      "\n",
      "[8 rows x 58 columns]\n",
      "\n",
      "Missing Values in Train Data:\n",
      "ps_car_03_cat    411231\n",
      "ps_car_05_cat    266551\n",
      "ps_reg_03        107772\n",
      "ps_car_14         42620\n",
      "ps_car_07_cat     11489\n",
      "ps_ind_05_cat      5809\n",
      "ps_car_09_cat       569\n",
      "ps_ind_02_cat       216\n",
      "ps_car_01_cat       107\n",
      "ps_ind_04_cat        83\n",
      "ps_car_02_cat         5\n",
      "ps_car_11             5\n",
      "ps_car_12             1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHFCAYAAAAwv7dvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9uklEQVR4nO3dfVwVdf7//+cJ5YgEJ5SL41FSuljS8KJwl9A1LBUtkW270KJINiNbTJdFVz/aZ0vdDdIMK93sYrestGXbNdrtYxKkhpmihFKipm1paIKY4sELBMP5/tGP+XXESxo7oo/77Ta3m/Oe15l5nTHk2bznzLEZhmEIAAAAP9ol3m4AAADgQkGwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACcEI2m+2Mlg8//NDbrXrYtGmTpk6dqu3bt59R/fz58z3eT5s2beR0OnXTTTcpKytLVVVVTV4zdepU2Wy2s+rr8OHDmjp16lmfrxMdq0uXLkpISDir/ZzOm2++qWeeeeaE22w2m6ZOnWrp8YALVStvNwDg/LR69WqP9T/96U9avny5li1b5jHerVu3n7Kt09q0aZOmTZum/v37q0uXLmf8uldffVXXXHONjh49qqqqKq1cuVIzZszQrFmz9I9//EMDBw40ax988EENGTLkrPo6fPiwpk2bJknq37//Gb+uOcdqjjfffFNlZWVKT09vsm316tXq1KnTOe8BuBAQrACc0A033OCxHhISoksuuaTJeHMdPnxYbdu2tWRfVoiKilLv3r3N9TvuuEO///3v9ctf/lK33367vvjiC4WFhUmSOnXqdM6DRuP5+SmOdTpW/Z0DFwOmAgE021/+8hfdeOONCg0Nlb+/v7p3766ZM2fq6NGjHnX9+/dXVFSUVqxYoT59+qht27Z64IEHJEk7d+7UnXfeqYCAAF122WW69957VVxcLJvNpvnz53vs55NPPlFiYqLatWunNm3a6LrrrtNbb71lbp8/f77uuusuSdJNN91kTu8dv58zdfnll+vpp5/WgQMH9OKLL5rjJ5qeW7Zsmfr376/27dvLz89Pl19+ue644w4dPnxY27dvV0hIiCRp2rRpZl8pKSke+1u3bp3uvPNOBQUF6corrzzpsRrl5uaqR48eatOmja644go999xzHtsbpzmPnxb98MMPPaZx+/fvr8WLF+vrr7/2mBZtdKKpwLKyMv3qV79SUFCQ2rRpo169eum111474XH+/ve/69FHH5XL5VJgYKAGDhyoLVu2nPzEAy0YV6wANNuXX36ppKQkRUREyNfXV59++qmeeOIJff7553rllVc8aisqKnTfffdp4sSJyszM1CWXXKJDhw7ppptu0r59+zRjxgxdddVVysvL04gRI5oca/ny5RoyZIhiYmL0wgsvyOFwKCcnRyNGjNDhw4eVkpKioUOHKjMzU1OmTNFf/vIXXX/99ZJkhpTmuPXWW+Xj46MVK1actGb79u0aOnSo+vXrp1deeUWXXXaZvvnmG+Xl5am+vl4dOnRQXl6ehgwZolGjRunBBx+UJDNsNbr99tt199136+GHH9ahQ4dO2VdpaanS09M1depUOZ1OLVy4UL/73e9UX1+vCRMmnNV7fP755/XQQw/pyy+/VG5u7mnrt2zZoj59+ig0NFTPPfec2rdvrwULFiglJUW7d+/WxIkTPeqnTJmivn376q9//atqamo0adIkDRs2TJs3b5aPj89Z9Qqc7whWAJotOzvb/POxY8fUr18/tW/fXr/5zW/09NNPKygoyNy+b98+/fOf/9TNN99sjj3//PP673//qyVLlpj3EcXHx+vw4cMeV4gkKS0tTddee62WLVumVq2+/6dr8ODB+vbbbzVlyhTdf//9CgkJ0dVXXy3p+3u/rJjC8vf3V3BwsHbt2nXSmpKSEh05ckRPPfWUevbsaY4nJSWZf46Ojpb0/TTiyfoaOXKkeR/W6ezatUvr1683j3fLLbeoqqpKf/rTn5SWlnZW06zdunXTZZddJrvdfkbnbOrUqaqvr9fy5csVHh4u6fsAun//fk2bNk2jR4+Ww+Hw2P+CBQvMdR8fHw0fPlzFxcVMM+KCw1QggGZbv369EhMT1b59e/n4+Kh169a6//771dDQoK1bt3rUBgUFeYQqSSosLFRAQECTm7Pvuecej/X//ve/+vzzz3XvvfdKkr777jtzufXWW1VRUXFOp5YMwzjl9l69esnX11cPPfSQXnvtNX311VfNOs4dd9xxxrXXXnutR4iTvg9yNTU1WrduXbOOf6aWLVumAQMGmKGqUUpKig4fPtzkgw+JiYke6z169JAkff311+e0T8AbCFYAmqW8vFz9+vXTN998o2effVYfffSRiouL9Ze//EWSVFtb61HfoUOHJvvYu3eveUP4Dx0/tnv3bknShAkT1Lp1a48lLS1NkvTtt99a8r6Od+jQIe3du1cul+ukNVdeeaU++OADhYaGasyYMbryyit15ZVX6tlnnz2rY53oHJ2M0+k86djevXvP6rhna+/evSfstfEcHX/89u3be6zb7XZJTf8bAS4ETAUCaJZ33nlHhw4d0ttvv63OnTub46WlpSesP9EN2O3bt9fatWubjFdWVnqsBwcHS5ImT56s22+//YT7j4yMPNPWz8rixYvV0NBw2kck9OvXT/369VNDQ4M++eQTzZkzR+np6QoLC9Pdd999Rsc6m2djHX+OfjjWGGTatGkjSaqrq/Oo+7EhtH379qqoqGgy3jhd2vj3BVyMuGIFoFkaQ0Dj1Qfp+ymzl19++Yz3ERcXpwMHDmjJkiUe4zk5OR7rkZGRuvrqq/Xpp5+qd+/eJ1wCAgI8+rHiakh5ebkmTJggh8Oh0aNHn9FrfHx8FBMTY165a5yWs/oqzcaNG/Xpp596jL355psKCAgwb9pvfI7XZ5995lH3n//8p8n+7Hb7Gfc2YMAALVu2rMl9Z6+//rratm3LfVO4qHHFCkCzDBo0SL6+vrrnnns0ceJEHTlyRPPmzVN1dfUZ72PkyJGaPXu27rvvPv35z3/WVVddpSVLluj999+XJF1yyf///34vvviibrnlFg0ePFgpKSnq2LGj9u3bp82bN2vdunX65z//Ken751FJ0ksvvaSAgAC1adNGERERTaajjldWVmbet1VVVaWPPvpIr776qnx8fJSbm9vkE3w/9MILL2jZsmUaOnSoLr/8ch05csT8VGTjg0UDAgLUuXNn/fvf/9aAAQPUrl07BQcHn9VDTH/I5XIpMTFRU6dOVYcOHbRgwQIVFBRoxowZ5o3rP//5zxUZGakJEybou+++U1BQkHJzc7Vy5com++vevbvefvttzZs3T9HR0brkkks8nuv1Q48//rj+7//+TzfddJMee+wxtWvXTgsXLtTixYs1c+ZMjxvXgYuOAQBnYOTIkYa/v7/H2Lvvvmv07NnTaNOmjdGxY0fjD3/4g7FkyRJDkrF8+XKzLi4uzrj22mtPuN/y8nLj9ttvNy699FIjICDAuOOOO4z33nvPkGT8+9//9qj99NNPjeHDhxuhoaFG69atDafTadx8883GCy+84FH3zDPPGBEREYaPj48hyXj11VdP+r5effVVQ5K5+Pr6GqGhoUZcXJyRmZlpVFVVNXnN448/bvzwn8/Vq1cbv/71r43OnTsbdrvdaN++vREXF2f85z//8XjdBx98YFx33XWG3W43JBkjR4702N+ePXtOeyzDMIzOnTsbQ4cONf71r38Z1157reHr62t06dLFyM7ObvL6rVu3GvHx8UZgYKAREhJijB071li8eHGTv6N9+/YZd955p3HZZZcZNpvN45iSjMcff9xjvxs2bDCGDRtmOBwOw9fX1+jZs2eT87x8+XJDkvHPf/7TY3zbtm2n/XsBWiqbYZzm4y4A8BPLzMzU//7v/6q8vNzrTx0HgLPBVCAAr5o7d64kmd/Tt2zZMj333HO67777CFUAWhyCFQCvatu2rWbPnq3t27errq5Ol19+uSZNmqT//d//9XZrAHDWmAoEAACwCI9bAAAAsIjXg9U333yj++67T+3bt1fbtm3Vq1cvlZSUmNsNw9DUqVPlcrnk5+en/v37a+PGjR77qKur09ixYxUcHCx/f38lJiZq586dHjXV1dVKTk6Ww+GQw+FQcnKy9u/f71FTXl6uYcOGmd8NNm7cONXX13vUbNiwQXFxcfLz81PHjh01ffr0037dBQAAuDh4NVhVV1erb9++at26tZYsWaJNmzbp6aef1mWXXWbWzJw5U9nZ2Zo7d66Ki4vldDo1aNAgHThwwKxJT09Xbm6ucnJytHLlSh08eFAJCQlqaGgwa5KSklRaWqq8vDzl5eWptLRUycnJ5vaGhgYNHTpUhw4d0sqVK5WTk6NFixZp/PjxZk1NTY0GDRokl8ul4uJizZkzR7NmzfL4IloAAHDx8uo9Vv/zP/+jjz/+WB999NEJtxuGIZfLpfT0dE2aNEnS91enwsLCNGPGDI0ePVput1shISF64403NGLECEnff61CeHi43nvvPQ0ePFibN29Wt27dVFRUpJiYGElSUVGRYmNj9fnnnysyMlJLlixRQkKCduzYYX7fVU5OjlJSUlRVVaXAwEDNmzdPkydP1u7du82nKD/55JOaM2eOdu7ceUZfR3Hs2DHt2rVLAQEBZ/X1FQAAwHsMw9CBAwfkcrk8Hl58okKv6dq1q5Genm7ceeedRkhIiNGrVy/jpZdeMrd/+eWXhiRj3bp1Hq9LTEw07r//fsMwDGPp0qWGJGPfvn0eNT169DAee+wxwzAM429/+5vhcDiaHN/hcBivvPKKYRiG8cc//tHo0aOHx/Z9+/YZkoxly5YZhmEYycnJRmJiokfNunXrDEnGV199dcL3eOTIEcPtdpvLpk2bPB5GyMLCwsLCwtJylh07dpwy23j1cQtfffWV5s2bp4yMDE2ZMkVr167VuHHjZLfbdf/995tfKHr8N92HhYXp66+/lvT9l476+voqKCioSU3j6ysrKxUaGtrk+KGhoR41xx8nKChIvr6+HjXHf/1E42sqKysVERHR5BhZWVmaNm1ak/EdO3YoMDDwxCcGAACcV2pqahQeHm5+L+nJeDVYHTt2TL1791ZmZqYk6brrrtPGjRs1b9483X///Wbd8VNmhmGcdhrt+JoT1VtRY/x/M6kn62fy5MnKyMgw1xv/YgIDAwlWAAC0MKfLH169eb1Dhw7q1q2bx1jXrl1VXl4uSXI6nZJkXjFqVFVVZV4pcjqdqq+vb/LFr8fX7N69u8nx9+zZ41Fz/HGqq6t19OjRU9ZUVVVJanpVrZHdbjdDFGEKAIALm1eDVd++fbVlyxaPsa1bt6pz586SpIiICDmdThUUFJjb6+vrVVhYqD59+kiSoqOj1bp1a4+aiooKlZWVmTWxsbFyu91au3atWbNmzRq53W6PmrKyMlVUVJg1+fn5stvtio6ONmtWrFjh8QiG/Px8uVyuZn9DPQAAuICc8g6sc2zt2rVGq1atjCeeeML44osvjIULFxpt27Y1FixYYNY8+eSThsPhMN5++21jw4YNxj333GN06NDBqKmpMWsefvhho1OnTsYHH3xgrFu3zrj55puNnj17Gt99951ZM2TIEKNHjx7G6tWrjdWrVxvdu3c3EhISzO3fffedERUVZQwYMMBYt26d8cEHHxidOnUyHnnkEbNm//79RlhYmHHPPfcYGzZsMN5++20jMDDQmDVr1hm/Z7fbbUgy3G53c08bAAD4iZ3p72+vBivDMIx3333XiIqKMux2u3HNNdd4fCrQMAzj2LFjxuOPP244nU7DbrcbN954o7FhwwaPmtraWuORRx4x2rVrZ/j5+RkJCQlGeXm5R83evXuNe++91wgICDACAgKMe++916iurvao+frrr42hQ4cafn5+Rrt27YxHHnnEOHLkiEfNZ599ZvTr18+w2+2G0+k0pk6dahw7duyM3y/BCgCAludMf3/zXYE/sZqaGjkcDrndbu63AgCghTjT399e/0obAACACwXBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIq283QCsF/2H173dAnBeKnnqfm+3AOACxxUrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCJeDVZTp06VzWbzWJxOp7ndMAxNnTpVLpdLfn5+6t+/vzZu3Oixj7q6Oo0dO1bBwcHy9/dXYmKidu7c6VFTXV2t5ORkORwOORwOJScna//+/R415eXlGjZsmPz9/RUcHKxx48apvr7eo2bDhg2Ki4uTn5+fOnbsqOnTp8swDGtPCgAAaLG8fsXq2muvVUVFhbls2LDB3DZz5kxlZ2dr7ty5Ki4ultPp1KBBg3TgwAGzJj09Xbm5ucrJydHKlSt18OBBJSQkqKGhwaxJSkpSaWmp8vLylJeXp9LSUiUnJ5vbGxoaNHToUB06dEgrV65UTk6OFi1apPHjx5s1NTU1GjRokFwul4qLizVnzhzNmjVL2dnZ5/gMAQCAlqKV1xto1crjKlUjwzD0zDPP6NFHH9Xtt98uSXrttdcUFhamN998U6NHj5bb7dbf/vY3vfHGGxo4cKAkacGCBQoPD9cHH3ygwYMHa/PmzcrLy1NRUZFiYmIkSS+//LJiY2O1ZcsWRUZGKj8/X5s2bdKOHTvkcrkkSU8//bRSUlL0xBNPKDAwUAsXLtSRI0c0f/582e12RUVFaevWrcrOzlZGRoZsNttPdMYAAMD5yutXrL744gu5XC5FRETo7rvv1ldffSVJ2rZtmyorKxUfH2/W2u12xcXFadWqVZKkkpISHT161KPG5XIpKirKrFm9erUcDocZqiTphhtukMPh8KiJiooyQ5UkDR48WHV1dSopKTFr4uLiZLfbPWp27dql7du3n/T91dXVqaamxmMBAAAXJq8Gq5iYGL3++ut6//339fLLL6uyslJ9+vTR3r17VVlZKUkKCwvzeE1YWJi5rbKyUr6+vgoKCjplTWhoaJNjh4aGetQcf5ygoCD5+vqesqZxvbHmRLKyssx7uxwOh8LDw099UgAAQIvl1WB1yy236I477lD37t01cOBALV68WNL3U36Njp9iMwzjtNNux9ecqN6KmsYb10/Vz+TJk+V2u81lx44dp+wdAAC0XF6fCvwhf39/de/eXV988YV539XxV4OqqqrMK0VOp1P19fWqrq4+Zc3u3bubHGvPnj0eNccfp7q6WkePHj1lTVVVlaSmV9V+yG63KzAw0GMBAAAXpvMqWNXV1Wnz5s3q0KGDIiIi5HQ6VVBQYG6vr69XYWGh+vTpI0mKjo5W69atPWoqKipUVlZm1sTGxsrtdmvt2rVmzZo1a+R2uz1qysrKVFFRYdbk5+fLbrcrOjrarFmxYoXHIxjy8/PlcrnUpUsX608GAABocbwarCZMmKDCwkJt27ZNa9as0Z133qmamhqNHDlSNptN6enpyszMVG5ursrKypSSkqK2bdsqKSlJkuRwODRq1CiNHz9eS5cu1fr163XfffeZU4uS1LVrVw0ZMkSpqakqKipSUVGRUlNTlZCQoMjISElSfHy8unXrpuTkZK1fv15Lly7VhAkTlJqaal5hSkpKkt1uV0pKisrKypSbm6vMzEw+EQgAAExefdzCzp07dc899+jbb79VSEiIbrjhBhUVFalz586SpIkTJ6q2tlZpaWmqrq5WTEyM8vPzFRAQYO5j9uzZatWqlYYPH67a2loNGDBA8+fPl4+Pj1mzcOFCjRs3zvz0YGJioubOnWtu9/Hx0eLFi5WWlqa+ffvKz89PSUlJmjVrllnjcDhUUFCgMWPGqHfv3goKClJGRoYyMjLO9WkCAAAthM3g0eE/qZqaGjkcDrnd7nN2v1X0H14/J/sFWrqSp+73dgsAWqgz/f19Xt1jBQAA0JIRrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxy3gSrrKws2Ww2paenm2OGYWjq1KlyuVzy8/NT//79tXHjRo/X1dXVaezYsQoODpa/v78SExO1c+dOj5rq6molJyfL4XDI4XAoOTlZ+/fv96gpLy/XsGHD5O/vr+DgYI0bN0719fUeNRs2bFBcXJz8/PzUsWNHTZ8+XYZhWHoeAABAy3VeBKvi4mK99NJL6tGjh8f4zJkzlZ2drblz56q4uFhOp1ODBg3SgQMHzJr09HTl5uYqJydHK1eu1MGDB5WQkKCGhgazJikpSaWlpcrLy1NeXp5KS0uVnJxsbm9oaNDQoUN16NAhrVy5Ujk5OVq0aJHGjx9v1tTU1GjQoEFyuVwqLi7WnDlzNGvWLGVnZ5/DMwMAAFqSVt5u4ODBg7r33nv18ssv689//rM5bhiGnnnmGT366KO6/fbbJUmvvfaawsLC9Oabb2r06NFyu93629/+pjfeeEMDBw6UJC1YsEDh4eH64IMPNHjwYG3evFl5eXkqKipSTEyMJOnll19WbGystmzZosjISOXn52vTpk3asWOHXC6XJOnpp59WSkqKnnjiCQUGBmrhwoU6cuSI5s+fL7vdrqioKG3dulXZ2dnKyMiQzWb7ic8cAAA433j9itWYMWM0dOhQMxg12rZtmyorKxUfH2+O2e12xcXFadWqVZKkkpISHT161KPG5XIpKirKrFm9erUcDocZqiTphhtukMPh8KiJiooyQ5UkDR48WHV1dSopKTFr4uLiZLfbPWp27dql7du3n/T91dXVqaamxmMBAAAXJq8Gq5ycHK1bt05ZWVlNtlVWVkqSwsLCPMbDwsLMbZWVlfL19VVQUNApa0JDQ5vsPzQ01KPm+OMEBQXJ19f3lDWN6401J5KVlWXe2+VwOBQeHn7SWgAA0LJ5LVjt2LFDv/vd77RgwQK1adPmpHXHT7EZhnHaabfja05Ub0VN443rp+pn8uTJcrvd5rJjx45T9g4AAFourwWrkpISVVVVKTo6Wq1atVKrVq1UWFio5557Tq1atTrp1aCqqipzm9PpVH19vaqrq09Zs3v37ibH37Nnj0fN8ceprq7W0aNHT1lTVVUlqelVtR+y2+0KDAz0WAAAwIXJa8FqwIAB2rBhg0pLS82ld+/euvfee1VaWqorrrhCTqdTBQUF5mvq6+tVWFioPn36SJKio6PVunVrj5qKigqVlZWZNbGxsXK73Vq7dq1Zs2bNGrndbo+asrIyVVRUmDX5+fmy2+2Kjo42a1asWOHxCIb8/Hy5XC516dLF+hMEAABaHK99KjAgIEBRUVEeY/7+/mrfvr05np6erszMTF199dW6+uqrlZmZqbZt2yopKUmS5HA4NGrUKI0fP17t27dXu3btNGHCBHXv3t28Gb5r164aMmSIUlNT9eKLL0qSHnroISUkJCgyMlKSFB8fr27duik5OVlPPfWU9u3bpwkTJig1NdW8wpSUlKRp06YpJSVFU6ZM0RdffKHMzEw99thjfCIQAABIOg8et3AqEydOVG1trdLS0lRdXa2YmBjl5+crICDArJk9e7ZatWql4cOHq7a2VgMGDND8+fPl4+Nj1ixcuFDjxo0zPz2YmJiouXPnmtt9fHy0ePFipaWlqW/fvvLz81NSUpJmzZpl1jgcDhUUFGjMmDHq3bu3goKClJGRoYyMjJ/gTAAAgJbAZvDo8J9UTU2NHA6H3G73ObvfKvoPr5+T/QItXclT93u7BQAt1Jn+/vb6c6wAAAAuFAQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIs0KVjfffLP279/fZLympkY333zzj+0JAACgRWpWsPrwww9VX1/fZPzIkSP66KOPfnRTAAAALVGrsyn+7LPPzD9v2rRJlZWV5npDQ4Py8vLUsWNH67oDAABoQc4qWPXq1Us2m002m+2EU35+fn6aM2eOZc0BAAC0JGcVrLZt2ybDMHTFFVdo7dq1CgkJMbf5+voqNDRUPj4+ljcJAADQEpxVsOrcubMk6dixY+ekGQAAgJbsrILVD23dulUffvihqqqqmgStxx577Ec3BgAA0NI0K1i9/PLL+u1vf6vg4GA5nU7ZbDZzm81mI1gBAICLUrOC1Z///Gc98cQTmjRpktX9AAAAtFjNeo5VdXW17rrrLqt7AQAAaNGaFazuuusu5efnW90LAABAi9asqcCrrrpKf/zjH1VUVKTu3burdevWHtvHjRtnSXMAAAAtSbOC1UsvvaRLL71UhYWFKiws9Nhms9kIVgAA4KLUrKnAbdu2nXT56quvzng/8+bNU48ePRQYGKjAwEDFxsZqyZIl5nbDMDR16lS5XC75+fmpf//+2rhxo8c+6urqNHbsWAUHB8vf31+JiYnauXOnR011dbWSk5PlcDjkcDiUnJzc5Euky8vLNWzYMPn7+ys4OFjjxo1r8n2IGzZsUFxcnPz8/NSxY0dNnz5dhmGc8fsFAAAXtmYFK6t06tRJTz75pD755BN98sknuvnmm/WrX/3KDE8zZ85Udna25s6dq+LiYjmdTg0aNEgHDhww95Genq7c3Fzl5ORo5cqVOnjwoBISEtTQ0GDWJCUlqbS0VHl5ecrLy1NpaamSk5PN7Q0NDRo6dKgOHTqklStXKicnR4sWLdL48ePNmpqaGg0aNEgul0vFxcWaM2eOZs2apezs7J/gTAEAgJbAZjTjkssDDzxwyu2vvPJKsxtq166dnnrqKT3wwANyuVxKT083H+tQV1ensLAwzZgxQ6NHj5bb7VZISIjeeOMNjRgxQpK0a9cuhYeH67333tPgwYO1efNmdevWTUVFRYqJiZEkFRUVKTY2Vp9//rkiIyO1ZMkSJSQkaMeOHXK5XJKknJwcpaSkqKqqSoGBgZo3b54mT56s3bt3y263S5KefPJJzZkzRzt37vR4ltep1NTUyOFwyO12KzAwsNnn6VSi//D6Odkv0NKVPHW/t1sA0EKd6e/vZj9u4YdLVVWVli1bprfffrvJFNuZamhoUE5Ojg4dOqTY2Fht27ZNlZWVio+PN2vsdrvi4uK0atUqSVJJSYmOHj3qUeNyuRQVFWXWrF69Wg6HwwxVknTDDTfI4XB41ERFRZmhSpIGDx6suro6lZSUmDVxcXFmqGqs2bVrl7Zv396s9wwAAC4szbp5PTc3t8nYsWPHlJaWpiuuuOKs9rVhwwbFxsbqyJEjuvTSS5Wbm6tu3bqZoScsLMyjPiwsTF9//bUkqbKyUr6+vgoKCmpSU1lZadaEhoY2OW5oaKhHzfHHCQoKkq+vr0dNly5dmhyncVtERMQJ319dXZ3q6urM9ZqampOfDAAA0KJZdo/VJZdcot///veaPXv2Wb0uMjJSpaWlKioq0m9/+1uNHDlSmzZtMrcfP8VmGMZpp92OrzlRvRU1jbOop+onKyvLvGne4XAoPDz8lL0DAICWy9Kb17/88kt99913Z/UaX19fXXXVVerdu7eysrLUs2dPPfvss3I6nZJkXjFqVFVVZV4pcjqdqq+vV3V19Slrdu/e3eS4e/bs8ag5/jjV1dU6evToKWuqqqokNb2q9kOTJ0+W2+02lx07dpz6hAAAgBarWVOBGRkZHuuGYaiiokKLFy/WyJEjf1RDhmGorq5OERERcjqdKigo0HXXXSdJqq+vV2FhoWbMmCFJio6OVuvWrVVQUKDhw4dLkioqKlRWVqaZM2dKkmJjY+V2u7V27Vr94he/kCStWbNGbrdbffr0MWueeOIJVVRUqEOHDpKk/Px82e12RUdHmzVTpkxRfX29fH19zRqXy9VkivCH7Ha7x31ZAADgwtWsYLV+/XqP9UsuuUQhISF6+umnT/uJwR+aMmWKbrnlFoWHh+vAgQPKycnRhx9+qLy8PNlsNqWnpyszM1NXX321rr76amVmZqpt27ZKSkqSJDkcDo0aNUrjx49X+/bt1a5dO02YMEHdu3fXwIEDJUldu3bVkCFDlJqaqhdffFGS9NBDDykhIUGRkZGSpPj4eHXr1k3Jycl66qmntG/fPk2YMEGpqanmnf9JSUmaNm2aUlJSNGXKFH3xxRfKzMzUY489dsafCAQAABe2ZgWr5cuXW3Lw3bt3Kzk5WRUVFXI4HOrRo4fy8vI0aNAgSdLEiRNVW1urtLQ0VVdXKyYmRvn5+QoICDD3MXv2bLVq1UrDhw9XbW2tBgwYoPnz58vHx8esWbhwocaNG2d+ejAxMVFz5841t/v4+Gjx4sVKS0tT37595efnp6SkJM2aNcuscTgcKigo0JgxY9S7d28FBQUpIyOjydU7AABw8WrWc6wa7dmzR1u2bJHNZtPPfvYzhYSEWNnbBYnnWAHew3OsADTXOX2O1aFDh/TAAw+oQ4cOuvHGG9WvXz+5XC6NGjVKhw8fbnbTAAAALVmzglVGRoYKCwv17rvvav/+/dq/f7/+/e9/q7Cw0ONrYAAAAC4mzbrHatGiRfrXv/6l/v37m2O33nqr/Pz8NHz4cM2bN8+q/gAAAFqMZl2xOnz48Amf3RQaGspUIAAAuGg1K1jFxsbq8ccf15EjR8yx2tpaTZs2TbGxsZY1BwAA0JI0ayrwmWee0S233KJOnTqpZ8+estlsKi0tld1uV35+vtU9AgAAtAjNClbdu3fXF198oQULFujzzz+XYRi6++67de+998rPz8/qHgEAAFqEZgWrrKwshYWFKTU11WP8lVde0Z49ezRp0iRLmgMAAGhJmnWP1Ysvvqhrrrmmyfi1116rF1544Uc3BQAA0BI1K1hVVlaaX1b8QyEhIaqoqPjRTQEAALREzQpW4eHh+vjjj5uMf/zxx3K5XD+6KQAAgJaoWfdYPfjgg0pPT9fRo0d18803S5KWLl2qiRMn8uR1AABw0WpWsJo4caL27duntLQ01dfXS5LatGmjSZMmafLkyZY2CAAA0FI0K1jZbDbNmDFDf/zjH7V582b5+fnp6quvlt1ut7o/AACAFqNZwarRpZdeqp///OdW9QIAANCiNevmdQAAADRFsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIt4NVhlZWXp5z//uQICAhQaGqrbbrtNW7Zs8agxDENTp06Vy+WSn5+f+vfvr40bN3rU1NXVaezYsQoODpa/v78SExO1c+dOj5rq6molJyfL4XDI4XAoOTlZ+/fv96gpLy/XsGHD5O/vr+DgYI0bN0719fUeNRs2bFBcXJz8/PzUsWNHTZ8+XYZhWHdSAABAi+XVYFVYWKgxY8aoqKhIBQUF+u677xQfH69Dhw6ZNTNnzlR2drbmzp2r4uJiOZ1ODRo0SAcOHDBr0tPTlZubq5ycHK1cuVIHDx5UQkKCGhoazJqkpCSVlpYqLy9PeXl5Ki0tVXJysrm9oaFBQ4cO1aFDh7Ry5Url5ORo0aJFGj9+vFlTU1OjQYMGyeVyqbi4WHPmzNGsWbOUnZ19js8UAABoCWzGeXS5Zc+ePQoNDVVhYaFuvPFGGYYhl8ul9PR0TZo0SdL3V6fCwsI0Y8YMjR49Wm63WyEhIXrjjTc0YsQISdKuXbsUHh6u9957T4MHD9bmzZvVrVs3FRUVKSYmRpJUVFSk2NhYff7554qMjNSSJUuUkJCgHTt2yOVySZJycnKUkpKiqqoqBQYGat68eZo8ebJ2794tu90uSXryySc1Z84c7dy5Uzab7bTvsaamRg6HQ263W4GBgefiNCr6D6+fk/0CLV3JU/d7uwUALdSZ/v4+r+6xcrvdkqR27dpJkrZt26bKykrFx8ebNXa7XXFxcVq1apUkqaSkREePHvWocblcioqKMmtWr14th8NhhipJuuGGG+RwODxqoqKizFAlSYMHD1ZdXZ1KSkrMmri4ODNUNdbs2rVL27dvP+F7qqurU01NjccCAAAuTOdNsDIMQxkZGfrlL3+pqKgoSVJlZaUkKSwszKM2LCzM3FZZWSlfX18FBQWdsiY0NLTJMUNDQz1qjj9OUFCQfH19T1nTuN5Yc7ysrCzzvi6Hw6Hw8PDTnAkAANBSnTfB6pFHHtFnn32mv//97022HT/FZhjGaafdjq85Ub0VNY0zqSfrZ/LkyXK73eayY8eOU/YNAABarvMiWI0dO1b/+c9/tHz5cnXq1MkcdzqdkppeDaqqqjKvFDmdTtXX16u6uvqUNbt3725y3D179njUHH+c6upqHT169JQ1VVVVkppeVWtkt9sVGBjosQAAgAuTV4OVYRh65JFH9Pbbb2vZsmWKiIjw2B4RESGn06mCggJzrL6+XoWFherTp48kKTo6Wq1bt/aoqaioUFlZmVkTGxsrt9uttWvXmjVr1qyR2+32qCkrK1NFRYVZk5+fL7vdrujoaLNmxYoVHo9gyM/Pl8vlUpcuXSw6KwAAoKXyarAaM2aMFixYoDfffFMBAQGqrKxUZWWlamtrJX0/vZaenq7MzEzl5uaqrKxMKSkpatu2rZKSkiRJDodDo0aN0vjx47V06VKtX79e9913n7p3766BAwdKkrp27aohQ4YoNTVVRUVFKioqUmpqqhISEhQZGSlJio+PV7du3ZScnKz169dr6dKlmjBhglJTU82rTElJSbLb7UpJSVFZWZlyc3OVmZmpjIyMM/pEIAAAuLC18ubB582bJ0nq37+/x/irr76qlJQUSdLEiRNVW1urtLQ0VVdXKyYmRvn5+QoICDDrZ8+erVatWmn48OGqra3VgAEDNH/+fPn4+Jg1Cxcu1Lhx48xPDyYmJmru3Lnmdh8fHy1evFhpaWnq27ev/Pz8lJSUpFmzZpk1DodDBQUFGjNmjHr37q2goCBlZGQoIyPD6lMDAABaoPPqOVYXA55jBXgPz7EC0Fwt8jlWAAAALRnBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwAgAAsAjBCgAAwCJeDVYrVqzQsGHD5HK5ZLPZ9M4773hsNwxDU6dOlcvlkp+fn/r376+NGzd61NTV1Wns2LEKDg6Wv7+/EhMTtXPnTo+a6upqJScny+FwyOFwKDk5Wfv37/eoKS8v17Bhw+Tv76/g4GCNGzdO9fX1HjUbNmxQXFyc/Pz81LFjR02fPl2GYVh2PgAAQMvm1WB16NAh9ezZU3Pnzj3h9pkzZyo7O1tz585VcXGxnE6nBg0apAMHDpg16enpys3NVU5OjlauXKmDBw8qISFBDQ0NZk1SUpJKS0uVl5envLw8lZaWKjk52dze0NCgoUOH6tChQ1q5cqVycnK0aNEijR8/3qypqanRoEGD5HK5VFxcrDlz5mjWrFnKzs4+B2cGAAC0RDbjPLnkYrPZlJubq9tuu03S91erXC6X0tPTNWnSJEnfX50KCwvTjBkzNHr0aLndboWEhOiNN97QiBEjJEm7du1SeHi43nvvPQ0ePFibN29Wt27dVFRUpJiYGElSUVGRYmNj9fnnnysyMlJLlixRQkKCduzYIZfLJUnKyclRSkqKqqqqFBgYqHnz5mny5MnavXu37Ha7JOnJJ5/UnDlztHPnTtlstjN6nzU1NXI4HHK73QoMDLTyFJqi//D6Odkv0NKVPHW/t1sA0EKd6e/v8/Yeq23btqmyslLx8fHmmN1uV1xcnFatWiVJKikp0dGjRz1qXC6XoqKizJrVq1fL4XCYoUqSbrjhBjkcDo+aqKgoM1RJ0uDBg1VXV6eSkhKzJi4uzgxVjTW7du3S9u3bT/o+6urqVFNT47EAAIAL03kbrCorKyVJYWFhHuNhYWHmtsrKSvn6+iooKOiUNaGhoU32Hxoa6lFz/HGCgoLk6+t7yprG9caaE8nKyjLv7XI4HAoPDz/1GwcAAC3WeRusGh0/xWYYxmmn3Y6vOVG9FTWNs6in6mfy5Mlyu93msmPHjlP2DgAAWq7zNlg5nU5JTa8GVVVVmVeKnE6n6uvrVV1dfcqa3bt3N9n/nj17PGqOP051dbWOHj16ypqqqipJTa+q/ZDdbldgYKDHAgAALkznbbCKiIiQ0+lUQUGBOVZfX6/CwkL16dNHkhQdHa3WrVt71FRUVKisrMysiY2Nldvt1tq1a82aNWvWyO12e9SUlZWpoqLCrMnPz5fdbld0dLRZs2LFCo9HMOTn58vlcqlLly7WnwAAANDieDVYHTx4UKWlpSotLZX0/Q3rpaWlKi8vl81mU3p6ujIzM5Wbm6uysjKlpKSobdu2SkpKkiQ5HA6NGjVK48eP19KlS7V+/Xrdd9996t69uwYOHChJ6tq1q4YMGaLU1FQVFRWpqKhIqampSkhIUGRkpCQpPj5e3bp1U3JystavX6+lS5dqwoQJSk1NNa8wJSUlyW63KyUlRWVlZcrNzVVmZqYyMjLO+BOBAADgwtbKmwf/5JNPdNNNN5nrGRkZkqSRI0dq/vz5mjhxompra5WWlqbq6mrFxMQoPz9fAQEB5mtmz56tVq1aafjw4aqtrdWAAQM0f/58+fj4mDULFy7UuHHjzE8PJiYmejw7y8fHR4sXL1ZaWpr69u0rPz8/JSUladasWWaNw+FQQUGBxowZo969eysoKEgZGRlmzwAAAOfNc6wuFjzHCvAenmMFoLla/HOsAAAAWhqCFQAAgEUIVgAAABYhWAEAAFiEYAUAAGARghUAAIBFCFYAAAAWIVgBAABYhGAFAABgEYIVAACARQhWAAAAFiFYAQAAWIRgBQAAYBGCFQAAgEUIVgAAABYhWAEAAFiEYAUAAGARghUAAIBFCFYAAAAWIVgBAABYhGAFAABgEYIVAACARQhWAAAAFiFYAQAAWIRgBQAAYBGCFQAAgEUIVgAAABYhWAEAAFiEYAUAAGARghUAAIBFCFYAAAAWIVgBAABYhGAFAABgEYIVAACARQhWAAAAFiFYAQAAWIRgBQAAYBGCFQAAgEUIVgAAABYhWAEAAFiEYAUAAGCRVt5uAABw5sqnd/d2C8B56fLHNni7BUlcsQIAALAMwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKAADAIgQrAAAAixCsAAAALEKwaobnn39eERERatOmjaKjo/XRRx95uyUAAHAeIFidpX/84x9KT0/Xo48+qvXr16tfv3665ZZbVF5e7u3WAACAlxGszlJ2drZGjRqlBx98UF27dtUzzzyj8PBwzZs3z9utAQAALyNYnYX6+nqVlJQoPj7eYzw+Pl6rVq3yUlcAAOB8wZcwn4Vvv/1WDQ0NCgsL8xgPCwtTZWXlCV9TV1enuro6c93tdkuSampqzlmfDXW152zfQEt2Ln/ufioHjjR4uwXgvHSuf74b928YxinrCFbNYLPZPNYNw2gy1igrK0vTpk1rMh4eHn5OegNwco45D3u7BQDnSpbjJznMgQMH5HCc/FgEq7MQHBwsHx+fJlenqqqqmlzFajR58mRlZGSY68eOHdO+ffvUvn37k4YxXDhqamoUHh6uHTt2KDAw0NvtALAQP98XF8MwdODAAblcrlPWEazOgq+vr6Kjo1VQUKBf//rX5nhBQYF+9atfnfA1drtddrvdY+yyyy47l23iPBQYGMg/vMAFip/vi8eprlQ1IlidpYyMDCUnJ6t3796KjY3VSy+9pPLycj38MFMMAABc7AhWZ2nEiBHau3evpk+froqKCkVFRem9995T586dvd0aAADwMoJVM6SlpSktLc3bbaAFsNvtevzxx5tMBwNo+fj5xonYjNN9bhAAAABnhAeEAgAAWIRgBQAAYBGCFQAAgEUIVgAAABYhWAHnyPPPP6+IiAi1adNG0dHR+uijj7zdEgALrFixQsOGDZPL5ZLNZtM777zj7ZZwHiFYAefAP/7xD6Wnp+vRRx/V+vXr1a9fP91yyy0qLy/3dmsAfqRDhw6pZ8+emjt3rrdbwXmIxy0A50BMTIyuv/56zZs3zxzr2rWrbrvtNmVlZXmxMwBWstlsys3N1W233ebtVnCe4IoVYLH6+nqVlJQoPj7eYzw+Pl6rVq3yUlcAgJ8CwQqw2LfffquGhgaFhYV5jIeFhamystJLXQEAfgoEK+AcsdlsHuuGYTQZAwBcWAhWgMWCg4Pl4+PT5OpUVVVVk6tYAIALC8EKsJivr6+io6NVUFDgMV5QUKA+ffp4qSsAwE+hlbcbAC5EGRkZSk5OVu/evRUbG6uXXnpJ5eXlevjhh73dGoAf6eDBg/rvf/9rrm/btk2lpaVq166dLr/8ci92hvMBj1sAzpHnn39eM2fOVEVFhaKiojR79mzdeOON3m4LwI/04Ycf6qabbmoyPnLkSM2fP/+nbwjnFYIVAACARbjHCgAAwCIEKwAAAIsQrAAAACxCsAIAALAIwQoAAMAiBCsAAACLEKwAAAAsQrACAACwCMEKwEWtf//+Sk9P93YbpvOtHwBnh2AFAD9SfX29t1sAcJ4gWAG4aKWkpKiwsFDPPvusbDabbDabvvzyS40aNUoRERHy8/NTZGSknn322Savu+2225SVlSWXy6Wf/exnkqRVq1apV69eatOmjXr37q133nlHNptNpaWl5ms3bdqkW2+9VZdeeqnCwsKUnJysb7/99qT9bN++/ac6HQAs0MrbDQCAtzz77LPaunWroqKiNH36dElSUFCQOnXqpLfeekvBwcFatWqVHnroIXXo0EHDhw83X7t06VIFBgaqoKBAhmHowIEDGjZsmG699Va9+eab+vrrr5tM6VVUVCguLk6pqanKzs5WbW2tJk2apOHDh2vZsmUn7CckJOQnOx8AfjyCFYCLlsPhkK+vr9q2bSun02mOT5s2zfxzRESEVq1apbfeessjWPn7++uvf/2rfH19JUkvvPCCbDabXn75ZbVp00bdunXTN998o9TUVPM18+bN0/XXX6/MzExz7JVXXlF4eLi2bt2qn/3sZyfsB0DLQbACgOO88MIL+utf/6qvv/5atbW1qq+vV69evTxqunfvboYqSdqyZYt69OihNm3amGO/+MUvPF5TUlKi5cuX69JLL21yzC+//NKcUgTQchGsAOAH3nrrLf3+97/X008/rdjYWAUEBOipp57SmjVrPOr8/f091g3DkM1mazL2Q8eOHdOwYcM0Y8aMJsft0KGDRe8AgDcRrABc1Hx9fdXQ0GCuf/TRR+rTp4/S0tLMsS+//PK0+7nmmmu0cOFC1dXVyW63S5I++eQTj5rrr79eixYtUpcuXdSq1Yn/+T2+HwAtC58KBHBR69Kli9asWaPt27fr22+/1VVXXaVPPvlE77//vrZu3ao//vGPKi4uPu1+kpKSdOzYMT300EPavHmz3n//fc2aNUuSzCtZY8aM0b59+3TPPfdo7dq1+uqrr5Sfn68HHnjADFPH93Ps2LFz9+YBWI5gBeCiNmHCBPn4+Khbt24KCQnRkCFDdPvtt2vEiBGKiYnR3r17Pa5enUxgYKDeffddlZaWqlevXnr00Uf12GOPSZJ535XL5dLHH3+shoYGDR48WFFRUfrd734nh8OhSy655IT9lJeXn7s3D8ByNuP4mwAAAJZYuHChfvOb38jtdsvPz8/b7QD4CXCPFQBY5PXXX9cVV1yhjh076tNPPzWfUUWoAi4eBCsAsEhlZaUee+wxVVZWqkOHDrrrrrv0xBNPeLstAD8hpgIBAAAsws3rAAAAFiFYAQAAWIRgBQAAYBGCFQAAgEUIVgAAABYhWAEAAFiEYAUAAGARghUAAIBFCFYAAAAW+X940bt77tgHEAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Check data structure\n",
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)\n",
    "\n",
    "#look at the first couple lines of data in the structures\n",
    "print(\"Train Data:\\n\", train.head())\n",
    "print(\"Test Data:\\n\", test.head())\n",
    "\n",
    "#Description of test and train data\n",
    "print(\"Train Data Description:\\n\", train.describe())\n",
    "print(\"Test Data Description:\\n\", test.describe())\n",
    "\n",
    "# Count missing values (-1) in each column\n",
    "missing_values = (train == -1).sum()\n",
    "\n",
    "print(\"\\nMissing Values in Train Data:\")\n",
    "print(missing_values[missing_values > 0].sort_values(ascending=False))\n",
    "\n",
    "# Check target distribution (imbalance)\n",
    "sns.countplot(x=train[\"target\"])\n",
    "plt.title(\"Target Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b264b-02b1-4637-8d7e-fe1d17fca580",
   "metadata": {},
   "source": [
    "This data is a little hard to do in depth analysis on becuase the data provider has already normalized and changed a bunch of the values for us. This means that all the data is already represented as a number so we don't have to deal with strings or categorical data. Although from the kaggle description we do know some of what the data represents. For example the data that ends in cat is categorical data, bin represents binary data, and features without without either of those are either continuous or ordinal.\n",
    "\n",
    "We also can see that the data very heavily favors 0 in the target meaning that our models will probably want to favor 0 as the prediction unless we make an effort to change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d38d79-9552-43d4-83b7-aa44b2645d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the data\n",
    "# Assuming the target column is named 'target' and features are in other columns\n",
    "X_train = train.drop(columns=['target']).values\n",
    "y_train = train['target'].values\n",
    "\n",
    "X_test = test.drop(columns=['target']).values if 'target' in test else test.values\n",
    "y_test = test['target'].values if 'target' in test else None\n",
    "\n",
    "# Normalize features\n",
    "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "if X_test is not None:\n",
    "    X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5cb7f8-dbf3-47c5-a713-318a71e76fd9",
   "metadata": {},
   "source": [
    "We did the following to remove any missing data to give us a full data set to use. We replaced missing values with the median values for the feature. We also did some basic feature processing on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e14d5-3d62-46b2-9b8f-7e329aec0971",
   "metadata": {},
   "source": [
    "Here are the functions for a basic regression model we are going to run on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b960dc6f-7ec9-407b-bb74-13b4877fbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression model(without regularization)\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_cost(X, y, weights):\n",
    "    m = len(y)\n",
    "    predictions = sigmoid(np.dot(X, weights))\n",
    "    cost = -(1/m) * np.sum(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(X, y, weights, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    for i in range(iterations):\n",
    "        predictions = sigmoid(np.dot(X, weights))\n",
    "        gradient = np.dot(X.T, (predictions - y)) / m\n",
    "        weights -= learning_rate * gradient\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Cost {compute_cost(X, y, weights)}\")\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ede7ef-f77e-46f1-89b8-88595e40f2a0",
   "metadata": {},
   "source": [
    "Now we train the basic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22abaea9-be6f-45ab-882c-b757c732fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a bias term to the features\n",
    "X_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "weights = np.zeros(X_train.shape[1])\n",
    "\n",
    "# Hyperparameters Got 0.24293\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# # Train the model\n",
    "# weights = gradient_descent(X_train, y_train, weights, learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abe260",
   "metadata": {},
   "source": [
    "Now , let's evaluate the model on the test set and create a submission for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37fb919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate 0.0005 and 1000 iterations.\n",
      "Iteration 0: Cost 0.6930393892742953\n",
      "Iteration 100: Cost 0.6823961893777927\n",
      "Iteration 200: Cost 0.6720175459014507\n",
      "Iteration 300: Cost 0.6618966690754329\n",
      "Iteration 400: Cost 0.6520268914414707\n",
      "Iteration 500: Cost 0.6424016711497796\n",
      "Iteration 600: Cost 0.6330145946487905\n",
      "Iteration 700: Cost 0.6238593788146457\n",
      "Iteration 800: Cost 0.6149298725653107\n",
      "Iteration 900: Cost 0.6062200580019885\n",
      "Submission file 'submission_lr0.0005_iters1000.csv' created successfully.\n",
      "Training with learning rate 0.0005 and 1500 iterations.\n",
      "Iteration 0: Cost 0.6930393892742953\n",
      "Iteration 100: Cost 0.6823961893777927\n",
      "Iteration 200: Cost 0.6720175459014507\n",
      "Iteration 300: Cost 0.6618966690754329\n",
      "Iteration 400: Cost 0.6520268914414707\n",
      "Iteration 500: Cost 0.6424016711497796\n",
      "Iteration 600: Cost 0.6330145946487905\n",
      "Iteration 700: Cost 0.6238593788146457\n",
      "Iteration 800: Cost 0.6149298725653107\n",
      "Iteration 900: Cost 0.6062200580019885\n",
      "Iteration 1000: Cost 0.5977240511183214\n",
      "Iteration 1100: Cost 0.5894361021156319\n",
      "Iteration 1200: Cost 0.5813505953602476\n",
      "Iteration 1300: Cost 0.573462049016781\n",
      "Iteration 1400: Cost 0.5657651143891066\n",
      "Submission file 'submission_lr0.0005_iters1500.csv' created successfully.\n",
      "Training with learning rate 0.0005 and 2000 iterations.\n",
      "Iteration 0: Cost 0.6930393892742953\n",
      "Iteration 100: Cost 0.6823961893777927\n",
      "Iteration 200: Cost 0.6720175459014507\n",
      "Iteration 300: Cost 0.6618966690754329\n",
      "Iteration 400: Cost 0.6520268914414707\n",
      "Iteration 500: Cost 0.6424016711497796\n",
      "Iteration 600: Cost 0.6330145946487905\n",
      "Iteration 700: Cost 0.6238593788146457\n",
      "Iteration 800: Cost 0.6149298725653107\n",
      "Iteration 900: Cost 0.6062200580019885\n",
      "Iteration 1000: Cost 0.5977240511183214\n",
      "Iteration 1100: Cost 0.5894361021156319\n",
      "Iteration 1200: Cost 0.5813505953602476\n",
      "Iteration 1300: Cost 0.573462049016781\n",
      "Iteration 1400: Cost 0.5657651143891066\n",
      "Iteration 1500: Cost 0.5582545749987089\n",
      "Iteration 1600: Cost 0.550925345428102\n",
      "Iteration 1700: Cost 0.543772469955078\n",
      "Iteration 1800: Cost 0.5367911210017416\n",
      "Iteration 1900: Cost 0.5299765974205239\n",
      "Submission file 'submission_lr0.0005_iters2000.csv' created successfully.\n",
      "Training with learning rate 0.0005 and 3000 iterations.\n",
      "Iteration 0: Cost 0.6930393892742953\n",
      "Iteration 100: Cost 0.6823961893777927\n",
      "Iteration 200: Cost 0.6720175459014507\n",
      "Iteration 300: Cost 0.6618966690754329\n",
      "Iteration 400: Cost 0.6520268914414707\n",
      "Iteration 500: Cost 0.6424016711497796\n",
      "Iteration 600: Cost 0.6330145946487905\n",
      "Iteration 700: Cost 0.6238593788146457\n",
      "Iteration 800: Cost 0.6149298725653107\n",
      "Iteration 900: Cost 0.6062200580019885\n",
      "Iteration 1000: Cost 0.5977240511183214\n",
      "Iteration 1100: Cost 0.5894361021156319\n",
      "Iteration 1200: Cost 0.5813505953602476\n",
      "Iteration 1300: Cost 0.573462049016781\n",
      "Iteration 1400: Cost 0.5657651143891066\n",
      "Iteration 1500: Cost 0.5582545749987089\n",
      "Iteration 1600: Cost 0.550925345428102\n",
      "Iteration 1700: Cost 0.543772469955078\n",
      "Iteration 1800: Cost 0.5367911210017416\n",
      "Iteration 1900: Cost 0.5299765974205239\n",
      "Iteration 2000: Cost 0.5233243226377129\n",
      "Iteration 2100: Cost 0.5168298426734794\n",
      "Iteration 2200: Cost 0.5104888240558672\n",
      "Iteration 2300: Cost 0.5042970516448435\n",
      "Iteration 2400: Cost 0.49825042638116035\n",
      "Iteration 2500: Cost 0.4923449629735588\n",
      "Iteration 2600: Cost 0.48657678753667416\n",
      "Iteration 2700: Cost 0.480942135190916\n",
      "Iteration 2800: Cost 0.47543734763458173\n",
      "Iteration 2900: Cost 0.47005887069751073\n",
      "Submission file 'submission_lr0.0005_iters3000.csv' created successfully.\n",
      "Training with learning rate 0.001 and 1000 iterations.\n",
      "Iteration 0: Cost 0.6929316115631402\n",
      "Iteration 100: Cost 0.671913770424609\n",
      "Iteration 200: Cost 0.651926978625397\n",
      "Iteration 300: Cost 0.6329184054989727\n",
      "Iteration 400: Cost 0.6148372694197922\n",
      "Iteration 500: Cost 0.5976348982817805\n",
      "Iteration 600: Cost 0.581264759629732\n",
      "Iteration 700: Cost 0.5656824654825797\n",
      "Iteration 800: Cost 0.5508457563266514\n",
      "Iteration 900: Cost 0.5367144682157465\n",
      "Submission file 'submission_lr0.001_iters1000.csv' created successfully.\n",
      "Training with learning rate 0.001 and 1500 iterations.\n",
      "Iteration 0: Cost 0.6929316115631402\n",
      "Iteration 100: Cost 0.671913770424609\n",
      "Iteration 200: Cost 0.651926978625397\n",
      "Iteration 300: Cost 0.6329184054989727\n",
      "Iteration 400: Cost 0.6148372694197922\n",
      "Iteration 500: Cost 0.5976348982817805\n",
      "Iteration 600: Cost 0.581264759629732\n",
      "Iteration 700: Cost 0.5656824654825797\n",
      "Iteration 800: Cost 0.5508457563266514\n",
      "Iteration 900: Cost 0.5367144682157465\n",
      "Iteration 1000: Cost 0.5232504864065827\n",
      "Iteration 1100: Cost 0.5104176884901737\n",
      "Iteration 1200: Cost 0.49818187955519316\n",
      "Iteration 1300: Cost 0.4865107215386527\n",
      "Iteration 1400: Cost 0.4753736585809901\n",
      "Submission file 'submission_lr0.001_iters1500.csv' created successfully.\n",
      "Training with learning rate 0.001 and 2000 iterations.\n",
      "Iteration 0: Cost 0.6929316115631402\n",
      "Iteration 100: Cost 0.671913770424609\n",
      "Iteration 200: Cost 0.651926978625397\n",
      "Iteration 300: Cost 0.6329184054989727\n",
      "Iteration 400: Cost 0.6148372694197922\n",
      "Iteration 500: Cost 0.5976348982817805\n",
      "Iteration 600: Cost 0.581264759629732\n",
      "Iteration 700: Cost 0.5656824654825797\n",
      "Iteration 800: Cost 0.5508457563266514\n",
      "Iteration 900: Cost 0.5367144682157465\n",
      "Iteration 1000: Cost 0.5232504864065827\n",
      "Iteration 1100: Cost 0.5104176884901737\n",
      "Iteration 1200: Cost 0.49818187955519316\n",
      "Iteration 1300: Cost 0.4865107215386527\n",
      "Iteration 1400: Cost 0.4753736585809901\n",
      "Iteration 1500: Cost 0.46474183990449436\n",
      "Iteration 1600: Cost 0.45458804147297327\n",
      "Iteration 1700: Cost 0.44488658746353194\n",
      "Iteration 1800: Cost 0.43561327238501213\n",
      "Iteration 1900: Cost 0.4267452845089753\n",
      "Submission file 'submission_lr0.001_iters2000.csv' created successfully.\n",
      "Training with learning rate 0.001 and 3000 iterations.\n",
      "Iteration 0: Cost 0.6929316115631402\n",
      "Iteration 100: Cost 0.671913770424609\n",
      "Iteration 200: Cost 0.651926978625397\n",
      "Iteration 300: Cost 0.6329184054989727\n",
      "Iteration 400: Cost 0.6148372694197922\n",
      "Iteration 500: Cost 0.5976348982817805\n",
      "Iteration 600: Cost 0.581264759629732\n",
      "Iteration 700: Cost 0.5656824654825797\n",
      "Iteration 800: Cost 0.5508457563266514\n",
      "Iteration 900: Cost 0.5367144682157465\n",
      "Iteration 1000: Cost 0.5232504864065827\n",
      "Iteration 1100: Cost 0.5104176884901737\n",
      "Iteration 1200: Cost 0.49818187955519316\n",
      "Iteration 1300: Cost 0.4865107215386527\n",
      "Iteration 1400: Cost 0.4753736585809901\n",
      "Iteration 1500: Cost 0.46474183990449436\n",
      "Iteration 1600: Cost 0.45458804147297327\n",
      "Iteration 1700: Cost 0.44488658746353194\n",
      "Iteration 1800: Cost 0.43561327238501213\n",
      "Iteration 1900: Cost 0.4267452845089753\n",
      "Iteration 2000: Cost 0.4182611311349761\n",
      "Iteration 2100: Cost 0.4101405660895851\n",
      "Iteration 2200: Cost 0.40236451975546805\n",
      "Iteration 2300: Cost 0.394915031840482\n",
      "Iteration 2400: Cost 0.38777518702502334\n",
      "Iteration 2500: Cost 0.3809290535667834\n",
      "Iteration 2600: Cost 0.3743616248939087\n",
      "Iteration 2700: Cost 0.36805876417871625\n",
      "Iteration 2800: Cost 0.3620071518532497\n",
      "Iteration 2900: Cost 0.35619423600380706\n",
      "Submission file 'submission_lr0.001_iters3000.csv' created successfully.\n",
      "Training with learning rate 0.005 and 1000 iterations.\n",
      "Iteration 0: Cost 0.6920698785555588\n",
      "Iteration 100: Cost 0.5969221153190414\n",
      "Iteration 200: Cost 0.5226601808873914\n",
      "Iteration 300: Cost 0.46425087427692613\n",
      "Iteration 400: Cost 0.4178503070652221\n",
      "Iteration 500: Cost 0.380582881980962\n",
      "Iteration 600: Cost 0.3503143465226343\n",
      "Iteration 700: Cost 0.3254606937995367\n",
      "Iteration 800: Cost 0.3048405992035328\n",
      "Iteration 900: Cost 0.28756623963290223\n",
      "Submission file 'submission_lr0.005_iters1000.csv' created successfully.\n",
      "Training with learning rate 0.005 and 1500 iterations.\n",
      "Iteration 0: Cost 0.6920698785555588\n",
      "Iteration 100: Cost 0.5969221153190414\n",
      "Iteration 200: Cost 0.5226601808873914\n",
      "Iteration 300: Cost 0.46425087427692613\n",
      "Iteration 400: Cost 0.4178503070652221\n",
      "Iteration 500: Cost 0.380582881980962\n",
      "Iteration 600: Cost 0.3503143465226343\n",
      "Iteration 700: Cost 0.3254606937995367\n",
      "Iteration 800: Cost 0.3048405992035328\n",
      "Iteration 900: Cost 0.28756623963290223\n",
      "Iteration 1000: Cost 0.27296415670758495\n",
      "Iteration 1100: Cost 0.26051835838714615\n",
      "Iteration 1200: Cost 0.24982943764105256\n",
      "Iteration 1300: Cost 0.2405850882835434\n",
      "Iteration 1400: Cost 0.2325387032910246\n",
      "Submission file 'submission_lr0.005_iters1500.csv' created successfully.\n",
      "Training with learning rate 0.005 and 2000 iterations.\n",
      "Iteration 0: Cost 0.6920698785555588\n",
      "Iteration 100: Cost 0.5969221153190414\n",
      "Iteration 200: Cost 0.5226601808873914\n",
      "Iteration 300: Cost 0.46425087427692613\n",
      "Iteration 400: Cost 0.4178503070652221\n",
      "Iteration 500: Cost 0.380582881980962\n",
      "Iteration 600: Cost 0.3503143465226343\n",
      "Iteration 700: Cost 0.3254606937995367\n",
      "Iteration 800: Cost 0.3048405992035328\n",
      "Iteration 900: Cost 0.28756623963290223\n",
      "Iteration 1000: Cost 0.27296415670758495\n",
      "Iteration 1100: Cost 0.26051835838714615\n",
      "Iteration 1200: Cost 0.24982943764105256\n",
      "Iteration 1300: Cost 0.2405850882835434\n",
      "Iteration 1400: Cost 0.2325387032910246\n",
      "Iteration 1500: Cost 0.22549371554371603\n",
      "Iteration 1600: Cost 0.21929203890486432\n",
      "Iteration 1700: Cost 0.2138054573724416\n",
      "Iteration 1800: Cost 0.20892915083106223\n",
      "Iteration 1900: Cost 0.20457678259698484\n",
      "Submission file 'submission_lr0.005_iters2000.csv' created successfully.\n",
      "Training with learning rate 0.005 and 3000 iterations.\n",
      "Iteration 0: Cost 0.6920698785555588\n",
      "Iteration 100: Cost 0.5969221153190414\n",
      "Iteration 200: Cost 0.5226601808873914\n",
      "Iteration 300: Cost 0.46425087427692613\n",
      "Iteration 400: Cost 0.4178503070652221\n",
      "Iteration 500: Cost 0.380582881980962\n",
      "Iteration 600: Cost 0.3503143465226343\n",
      "Iteration 700: Cost 0.3254606937995367\n",
      "Iteration 800: Cost 0.3048405992035328\n",
      "Iteration 900: Cost 0.28756623963290223\n",
      "Iteration 1000: Cost 0.27296415670758495\n",
      "Iteration 1100: Cost 0.26051835838714615\n",
      "Iteration 1200: Cost 0.24982943764105256\n",
      "Iteration 1300: Cost 0.2405850882835434\n",
      "Iteration 1400: Cost 0.2325387032910246\n",
      "Iteration 1500: Cost 0.22549371554371603\n",
      "Iteration 1600: Cost 0.21929203890486432\n",
      "Iteration 1700: Cost 0.2138054573724416\n",
      "Iteration 1800: Cost 0.20892915083106223\n",
      "Iteration 1900: Cost 0.20457678259698484\n",
      "Iteration 2000: Cost 0.20067673867027933\n",
      "Iteration 2100: Cost 0.19716922380319563\n",
      "Iteration 2200: Cost 0.19400400056391706\n",
      "Iteration 2300: Cost 0.19113861504426816\n",
      "Iteration 2400: Cost 0.188536993917016\n",
      "Iteration 2500: Cost 0.18616832711661543\n",
      "Iteration 2600: Cost 0.18400617188461968\n",
      "Iteration 2700: Cost 0.18202772963285307\n",
      "Iteration 2800: Cost 0.18021325866826993\n",
      "Iteration 2900: Cost 0.1785455944404969\n",
      "Submission file 'submission_lr0.005_iters3000.csv' created successfully.\n",
      "Training with learning rate 0.01 and 1000 iterations.\n",
      "Iteration 0: Cost 0.6909939339984333\n",
      "Iteration 100: Cost 0.5219232594570349\n",
      "Iteration 200: Cost 0.41733747940939536\n",
      "Iteration 300: Cost 0.3499475526044885\n",
      "Iteration 400: Cost 0.3045705124876015\n",
      "Iteration 500: Cost 0.2727598500850447\n",
      "Iteration 600: Cost 0.24967118426110524\n",
      "Iteration 700: Cost 0.23241358944020898\n",
      "Iteration 800: Cost 0.21919137245317338\n",
      "Iteration 900: Cost 0.20884692215052364\n",
      "Submission file 'submission_lr0.01_iters1000.csv' created successfully.\n",
      "Training with learning rate 0.01 and 1500 iterations.\n",
      "Iteration 0: Cost 0.6909939339984333\n",
      "Iteration 100: Cost 0.5219232594570349\n",
      "Iteration 200: Cost 0.41733747940939536\n",
      "Iteration 300: Cost 0.3499475526044885\n",
      "Iteration 400: Cost 0.3045705124876015\n",
      "Iteration 500: Cost 0.2727598500850447\n",
      "Iteration 600: Cost 0.24967118426110524\n",
      "Iteration 700: Cost 0.23241358944020898\n",
      "Iteration 800: Cost 0.21919137245317338\n",
      "Iteration 900: Cost 0.20884692215052364\n",
      "Iteration 1000: Cost 0.2006086886554709\n",
      "Iteration 1100: Cost 0.19394704232013651\n",
      "Iteration 1200: Cost 0.1884888446543932\n",
      "Iteration 1300: Cost 0.1839651127455822\n",
      "Iteration 1400: Cost 0.1801779743360883\n",
      "Submission file 'submission_lr0.01_iters1500.csv' created successfully.\n",
      "Training with learning rate 0.01 and 2000 iterations.\n",
      "Iteration 0: Cost 0.6909939339984333\n",
      "Iteration 100: Cost 0.5219232594570349\n",
      "Iteration 200: Cost 0.41733747940939536\n",
      "Iteration 300: Cost 0.3499475526044885\n",
      "Iteration 400: Cost 0.3045705124876015\n",
      "Iteration 500: Cost 0.2727598500850447\n",
      "Iteration 600: Cost 0.24967118426110524\n",
      "Iteration 700: Cost 0.23241358944020898\n",
      "Iteration 800: Cost 0.21919137245317338\n",
      "Iteration 900: Cost 0.20884692215052364\n",
      "Iteration 1000: Cost 0.2006086886554709\n",
      "Iteration 1100: Cost 0.19394704232013651\n",
      "Iteration 1200: Cost 0.1884888446543932\n",
      "Iteration 1300: Cost 0.1839651127455822\n",
      "Iteration 1400: Cost 0.1801779743360883\n",
      "Iteration 1500: Cost 0.1769792246792327\n",
      "Iteration 1600: Cost 0.17425606399497567\n",
      "Iteration 1700: Cost 0.17192139702218776\n",
      "Iteration 1800: Cost 0.1699071009490414\n",
      "Iteration 1900: Cost 0.16815926713067314\n",
      "Submission file 'submission_lr0.01_iters2000.csv' created successfully.\n",
      "Training with learning rate 0.01 and 3000 iterations.\n",
      "Iteration 0: Cost 0.6909939339984333\n",
      "Iteration 100: Cost 0.5219232594570349\n",
      "Iteration 200: Cost 0.41733747940939536\n",
      "Iteration 300: Cost 0.3499475526044885\n",
      "Iteration 400: Cost 0.3045705124876015\n",
      "Iteration 500: Cost 0.2727598500850447\n",
      "Iteration 600: Cost 0.24967118426110524\n",
      "Iteration 700: Cost 0.23241358944020898\n",
      "Iteration 800: Cost 0.21919137245317338\n",
      "Iteration 900: Cost 0.20884692215052364\n",
      "Iteration 1000: Cost 0.2006086886554709\n",
      "Iteration 1100: Cost 0.19394704232013651\n",
      "Iteration 1200: Cost 0.1884888446543932\n",
      "Iteration 1300: Cost 0.1839651127455822\n",
      "Iteration 1400: Cost 0.1801779743360883\n",
      "Iteration 1500: Cost 0.1769792246792327\n",
      "Iteration 1600: Cost 0.17425606399497567\n",
      "Iteration 1700: Cost 0.17192139702218776\n",
      "Iteration 1800: Cost 0.1699071009490414\n",
      "Iteration 1900: Cost 0.16815926713067314\n",
      "Iteration 2000: Cost 0.16663478148771985\n",
      "Iteration 2100: Cost 0.1652988294055676\n",
      "Iteration 2200: Cost 0.1641230497604212\n",
      "Iteration 2300: Cost 0.16308415170418578\n",
      "Iteration 2400: Cost 0.162162865996327\n",
      "Iteration 2500: Cost 0.16134314133637262\n",
      "Iteration 2600: Cost 0.16061152227497558\n",
      "Iteration 2700: Cost 0.15995666319789137\n",
      "Iteration 2800: Cost 0.15936894533645832\n",
      "Iteration 2900: Cost 0.1588401725352023\n",
      "Submission file 'submission_lr0.01_iters3000.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1, 0.2]\n",
    "iterations_list = [500, 1000, 2000, 5000]\n",
    "\n",
    "learning_rates = [0.0005, 0.001, 0.005, 0.01]\n",
    "iterations_list = [1000, 1500, 2000, 3000]\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for iters in iterations_list:\n",
    "        print(f\"Training with learning rate {lr} and {iters} iterations.\")\n",
    "        weights = np.zeros(X_train.shape[1])\n",
    "        weights = gradient_descent(X_train, y_train, weights, lr, iters)\n",
    "\n",
    "        if y_test is None:  # Assuming test data does not have target labels\n",
    "            # Ensure the test dataset has an ID column\n",
    "            if 'id' in test.columns:\n",
    "                ids = test['id'].values\n",
    "            else:\n",
    "                raise ValueError(\"The test dataset must contain an 'ID' column for submission.\")\n",
    "\n",
    "            # Add a bias term to the test features\n",
    "            X_testTemp = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "            # Calculate probabilities using the sigmoid function\n",
    "            probabilities = sigmoid(np.dot(X_testTemp, weights))\n",
    "\n",
    "            # Create a DataFrame for submission\n",
    "            submission = pd.DataFrame({\n",
    "                'id': ids,\n",
    "                'target': probabilities\n",
    "            })\n",
    "\n",
    "            # Adjust the filename to include the learning rate and iterations\n",
    "            filename = f\"submission_lr{lr}_iters{iters}.csv\"\n",
    "            \n",
    "            # Save the submission file\n",
    "            submission.to_csv(filename, index=False)\n",
    "            print(f\"Submission file '{filename}' created successfully.\")\n",
    "        else:\n",
    "            print(\"Test dataset contains target labels. No submission file created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d25c1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde35be4-9717-4692-8231-696daa3aefa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "if y_test is None:  # Assuming test data does not have target labels\n",
    "    # Ensure the test dataset has an ID column\n",
    "    if 'id' in test.columns:\n",
    "        ids = test['id'].values\n",
    "    else:\n",
    "        raise ValueError(\"The test dataset must contain an 'ID' column for submission.\")\n",
    "\n",
    "    # Add a bias term to the test features\n",
    "    X_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "    # Calculate probabilities using the sigmoid function\n",
    "    probabilities = sigmoid(np.dot(X_test, weights))\n",
    "\n",
    "    # Create a DataFrame for submission\n",
    "    submission = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'target': probabilities\n",
    "    })\n",
    "\n",
    "    # Save the submission file\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file 'submission.csv' created successfully.\")\n",
    "else:\n",
    "    print(\"Test dataset contains target labels. No submission file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27182c52",
   "metadata": {},
   "source": [
    "This submission got a score of 0.2499 which is much better than our dummy submission which got a score of 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd37339-b0d9-496a-b8ff-1f40ac866f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4144e49b",
   "metadata": {},
   "source": [
    "## Training with learning rate 0.0005 and 1000 iterations.\n",
    "- **Submission file**: 'submission_lr0.0005_iters1000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.23213\n",
    "\n",
    "## Training with learning rate 0.0005 and 1500 iterations.\n",
    "- **Submission file**: 'submission_lr0.0005_iters1500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.23331\n",
    "\n",
    "## Training with learning rate 0.0005 and 2000 iterations.\n",
    "- **Submission file**: 'submission_lr0.0005_iters2000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.23441\n",
    "\n",
    "## Training with learning rate 0.0005 and 3000 iterations.\n",
    "- **Submission file**: 'submission_lr0.0005_iters3000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.23629\n",
    "\n",
    "## Training with learning rate 0.001 and 500 iterations.\n",
    "- **Submission file**: 'submission_lr0.001_iters500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.23213\n",
    "\n",
    "## Training with learning rate 0.001 and 1000 iterations.\n",
    "- **Submission file**: 'submission_lr0.001_iters1000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.3440\n",
    "\n",
    "## Training with learning rate 0.001 and 1500 iterations.\n",
    "- **Submission file**: 'submission_lr0.001_iters1500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.23629\n",
    "\n",
    "## Training with learning rate 0.001 and 2000 iterations.\n",
    "- **Submission file**: 'submission_lr0.001_iters2000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.23778\n",
    "\n",
    "## Training with learning rate 0.001 and 3000 iterations.\n",
    "- **Submission file**: 'submission_lr0.001_iters3000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.2982\n",
    "\n",
    "## Training with learning rate 0.001 and 5000 iterations.\n",
    "- **Submission file**: 'submission_lr0.001_iters5000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24174\n",
    "\n",
    "## Training with learning rate 0.005 and 1000 iterations.\n",
    "- **Submission file**: 'submission_lr0.005_iters1000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24174\n",
    "\n",
    "## Training with learning rate 0.005 and 1500 iterations.\n",
    "- **Submission file**: 'submission_lr0.005_iters1500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24258\n",
    "\n",
    "## Training with learning rate 0.005 and 2000 iterations.\n",
    "- **Submission file**: 'submission_lr0.005_iters2000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24293\n",
    "\n",
    "## Training with learning rate 0.005 and 3000 iterations.\n",
    "- **Submission file**: 'submission_lr0.005_iters3000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24320\n",
    "\n",
    "## Training with learning rate 0.01 and 500 iterations.\n",
    "- **Submission file**: 'submission_lr0.01_iters500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24174\n",
    "\n",
    "## Training with learning rate 0.01 and 1000 iterations.\n",
    "- **Submission file**: 'submission_lr0.01_iters1000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24293\n",
    "\n",
    "## Training with learning rate 0.01 and 1500 iterations.\n",
    "- **Submission file**: 'submission_lr0.01_iters1500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24320\n",
    "\n",
    "## Training with learning rate 0.01 and 2000 iterations.\n",
    "- **Submission file**: 'submission_lr0.01_iters2000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24330\n",
    "\n",
    "## Training with learning rate 0.01 and 3000 iterations.\n",
    "- **Submission file**: 'submission_lr0.01_iters3000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24333\n",
    "\n",
    "## Training with learning rate 0.01 and 5000 iterations.\n",
    "- **Submission file**: 'submission_lr0.01_iters5000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24313\n",
    "\n",
    "## Training with learning rate 0.1 and 500 iterations.\n",
    "- **Submission file**: 'submission_lr0.1_iters500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24312\n",
    "\n",
    "## Training with learning rate 0.1 and 1000 iterations.\n",
    "- **Submission file**: 'submission_lr0.1_iters1000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24240\n",
    "\n",
    "## Training with learning rate 0.1 and 2000 iterations.\n",
    "- **Submission file**: 'submission_lr0.1_iters2000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24191\n",
    "\n",
    "## Training with learning rate 0.1 and 5000 iterations.\n",
    "- **Submission file**: 'submission_lr0.1_iters5000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24179\n",
    "\n",
    "## Training with learning rate 0.2 and 500 iterations.\n",
    "- **Submission file**: 'submission_lr0.2_iters500.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24240\n",
    "\n",
    "## Training with learning rate 0.2 and 1000 iterations.\n",
    "- **Submission file**: 'submission_lr0.2_iters1000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24191\n",
    "\n",
    "## Training with learning rate 0.2 and 2000 iterations.\n",
    "- **Submission file**: 'submission_lr0.2_iters2000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.2418\n",
    "\n",
    "## Training with learning rate 0.2 and 5000 iterations.\n",
    "- **Submission file**: 'submission_lr0.2_iters5000.csv' created successfully.\n",
    "- **SCORE GOT**: 0.24178\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35125d1d",
   "metadata": {},
   "source": [
    "Training with learning rate 0.001 and 500 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Submission file 'submission_lr0.001_iters500.csv' created successfully.\n",
    "Training with learning rate 0.001 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Iteration 500: Cost 0.5976348982817805\n",
    "Iteration 600: Cost 0.581264759629732\n",
    "Iteration 700: Cost 0.5656824654825797\n",
    "Iteration 800: Cost 0.5508457563266514\n",
    "Iteration 900: Cost 0.5367144682157465\n",
    "Submission file 'submission_lr0.001_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.001 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Iteration 500: Cost 0.5976348982817805\n",
    "Iteration 600: Cost 0.581264759629732\n",
    "Iteration 700: Cost 0.5656824654825797\n",
    "Iteration 800: Cost 0.5508457563266514\n",
    "Iteration 900: Cost 0.5367144682157465\n",
    "Iteration 1000: Cost 0.5232504864065827\n",
    "Iteration 1100: Cost 0.5104176884901737\n",
    "Iteration 1200: Cost 0.49818187955519316\n",
    "Iteration 1300: Cost 0.4865107215386527\n",
    "Iteration 1400: Cost 0.4753736585809901\n",
    "Iteration 1500: Cost 0.46474183990449436\n",
    "Iteration 1600: Cost 0.45458804147297327\n",
    "Iteration 1700: Cost 0.44488658746353194\n",
    "Iteration 1800: Cost 0.43561327238501213\n",
    "Iteration 1900: Cost 0.4267452845089753\n",
    "Submission file 'submission_lr0.001_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.001 and 5000 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Iteration 500: Cost 0.5976348982817805\n",
    "Iteration 600: Cost 0.581264759629732\n",
    "Iteration 700: Cost 0.5656824654825797\n",
    "Iteration 800: Cost 0.5508457563266514\n",
    "Iteration 900: Cost 0.5367144682157465\n",
    "Iteration 1000: Cost 0.5232504864065827\n",
    "Iteration 1100: Cost 0.5104176884901737\n",
    "Iteration 1200: Cost 0.49818187955519316\n",
    "Iteration 1300: Cost 0.4865107215386527\n",
    "Iteration 1400: Cost 0.4753736585809901\n",
    "Iteration 1500: Cost 0.46474183990449436\n",
    "Iteration 1600: Cost 0.45458804147297327\n",
    "Iteration 1700: Cost 0.44488658746353194\n",
    "Iteration 1800: Cost 0.43561327238501213\n",
    "Iteration 1900: Cost 0.4267452845089753\n",
    "Iteration 2000: Cost 0.4182611311349761\n",
    "Iteration 2100: Cost 0.4101405660895851\n",
    "Iteration 2200: Cost 0.40236451975546805\n",
    "Iteration 2300: Cost 0.394915031840482\n",
    "Iteration 2400: Cost 0.38777518702502334\n",
    "Iteration 2500: Cost 0.3809290535667834\n",
    "Iteration 2600: Cost 0.3743616248939087\n",
    "Iteration 2700: Cost 0.36805876417871625\n",
    "Iteration 2800: Cost 0.3620071518532497\n",
    "Iteration 2900: Cost 0.35619423600380706\n",
    "Iteration 3000: Cost 0.35060818556309703\n",
    "Iteration 3100: Cost 0.34523784620494363\n",
    "Iteration 3200: Cost 0.3400726988366538\n",
    "Iteration 3300: Cost 0.33510282057760776\n",
    "Iteration 3400: Cost 0.3303188481087227\n",
    "Iteration 3500: Cost 0.32571194327568237\n",
    "Iteration 3600: Cost 0.3212737608287787\n",
    "Iteration 3700: Cost 0.31699641818353524\n",
    "Iteration 3800: Cost 0.31287246708864275\n",
    "Iteration 3900: Cost 0.3088948670909171\n",
    "Iteration 4000: Cost 0.30505696069075455\n",
    "Iteration 4100: Cost 0.3013524500857392\n",
    "Iteration 4200: Cost 0.2977753754045418\n",
    "Iteration 4300: Cost 0.2943200943378598\n",
    "Iteration 4400: Cost 0.29098126307788075\n",
    "Iteration 4500: Cost 0.28775381848244275\n",
    "Iteration 4600: Cost 0.2846329613847339\n",
    "Iteration 4700: Cost 0.2816141409739276\n",
    "Iteration 4800: Cost 0.27869304017656665\n",
    "Iteration 4900: Cost 0.2758655619727877\n",
    "Submission file 'submission_lr0.001_iters5000.csv' created successfully.\n",
    "Training with learning rate 0.01 and 500 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Submission file 'submission_lr0.01_iters500.csv' created successfully.\n",
    "Training with learning rate 0.01 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Iteration 500: Cost 0.2727598500850447\n",
    "Iteration 600: Cost 0.24967118426110524\n",
    "Iteration 700: Cost 0.23241358944020898\n",
    "Iteration 800: Cost 0.21919137245317338\n",
    "Iteration 900: Cost 0.20884692215052364\n",
    "Submission file 'submission_lr0.01_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.01 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Iteration 500: Cost 0.2727598500850447\n",
    "Iteration 600: Cost 0.24967118426110524\n",
    "Iteration 700: Cost 0.23241358944020898\n",
    "Iteration 800: Cost 0.21919137245317338\n",
    "Iteration 900: Cost 0.20884692215052364\n",
    "Iteration 1000: Cost 0.2006086886554709\n",
    "Iteration 1100: Cost 0.19394704232013651\n",
    "Iteration 1200: Cost 0.1884888446543932\n",
    "Iteration 1300: Cost 0.1839651127455822\n",
    "Iteration 1400: Cost 0.1801779743360883\n",
    "Iteration 1500: Cost 0.1769792246792327\n",
    "Iteration 1600: Cost 0.17425606399497567\n",
    "Iteration 1700: Cost 0.17192139702218776\n",
    "Iteration 1800: Cost 0.1699071009490414\n",
    "Iteration 1900: Cost 0.16815926713067314\n",
    "Submission file 'submission_lr0.01_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.01 and 5000 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Iteration 500: Cost 0.2727598500850447\n",
    "Iteration 600: Cost 0.24967118426110524\n",
    "Iteration 700: Cost 0.23241358944020898\n",
    "Iteration 800: Cost 0.21919137245317338\n",
    "Iteration 900: Cost 0.20884692215052364\n",
    "Iteration 1000: Cost 0.2006086886554709\n",
    "Iteration 1100: Cost 0.19394704232013651\n",
    "Iteration 1200: Cost 0.1884888446543932\n",
    "Iteration 1300: Cost 0.1839651127455822\n",
    "Iteration 1400: Cost 0.1801779743360883\n",
    "Iteration 1500: Cost 0.1769792246792327\n",
    "Iteration 1600: Cost 0.17425606399497567\n",
    "Iteration 1700: Cost 0.17192139702218776\n",
    "Iteration 1800: Cost 0.1699071009490414\n",
    "Iteration 1900: Cost 0.16815926713067314\n",
    "Iteration 2000: Cost 0.16663478148771985\n",
    "Iteration 2100: Cost 0.1652988294055676\n",
    "Iteration 2200: Cost 0.1641230497604212\n",
    "Iteration 2300: Cost 0.16308415170418578\n",
    "Iteration 2400: Cost 0.162162865996327\n",
    "Iteration 2500: Cost 0.16134314133637262\n",
    "Iteration 2600: Cost 0.16061152227497558\n",
    "Iteration 2700: Cost 0.15995666319789137\n",
    "Iteration 2800: Cost 0.15936894533645832\n",
    "Iteration 2900: Cost 0.1588401725352023\n",
    "Iteration 3000: Cost 0.1583633277653572\n",
    "Iteration 3100: Cost 0.15793237688592715\n",
    "Iteration 3200: Cost 0.1575421094427451\n",
    "Iteration 3300: Cost 0.15718800871669333\n",
    "Iteration 3400: Cost 0.15686614503068955\n",
    "Iteration 3500: Cost 0.15657308767293995\n",
    "Iteration 3600: Cost 0.15630583181259447\n",
    "Iteration 3700: Cost 0.15606173755977884\n",
    "Iteration 3800: Cost 0.15583847891728084\n",
    "Iteration 3900: Cost 0.15563400083115067\n",
    "Iteration 4000: Cost 0.1554464829052752\n",
    "Iteration 4100: Cost 0.15527430862504446\n",
    "Iteration 4200: Cost 0.1551160391557795\n",
    "Iteration 4300: Cost 0.1549703909562474\n",
    "Iteration 4400: Cost 0.15483621658667204\n",
    "Iteration 4500: Cost 0.154712488201972\n",
    "Iteration 4600: Cost 0.1545982833105063\n",
    "Iteration 4700: Cost 0.15449277245097703\n",
    "Iteration 4800: Cost 0.15439520849890126\n",
    "Iteration 4900: Cost 0.1543049173619686\n",
    "Submission file 'submission_lr0.01_iters5000.csv' created successfully.\n",
    "Training with learning rate 0.1 and 500 iterations.\n",
    "Iteration 0: Cost 0.6718590303808213\n",
    "Iteration 100: Cost 0.19939790632518023\n",
    "Iteration 200: Cost 0.16634833230631\n",
    "Iteration 300: Cost 0.15826074873213367\n",
    "Iteration 400: Cost 0.15540217311302632\n",
    "Submission file 'submission_lr0.1_iters500.csv' created successfully.\n",
    "Training with learning rate 0.1 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6718590303808213\n",
    "Iteration 100: Cost 0.19939790632518023\n",
    "Iteration 200: Cost 0.16634833230631\n",
    "Iteration 300: Cost 0.15826074873213367\n",
    "Iteration 400: Cost 0.15540217311302632\n",
    "Iteration 500: Cost 0.15420003963383697\n",
    "Iteration 600: Cost 0.15364108111549152\n",
    "Iteration 700: Cost 0.15336371935989337\n",
    "Iteration 800: Cost 0.1532196604340765\n",
    "Iteration 900: Cost 0.15314221917628276\n",
    "Submission file 'submission_lr0.1_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.1 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6718590303808213\n",
    "Iteration 100: Cost 0.19939790632518023\n",
    "Iteration 200: Cost 0.16634833230631\n",
    "Iteration 300: Cost 0.15826074873213367\n",
    "Iteration 400: Cost 0.15540217311302632\n",
    "Iteration 500: Cost 0.15420003963383697\n",
    "Iteration 600: Cost 0.15364108111549152\n",
    "Iteration 700: Cost 0.15336371935989337\n",
    "Iteration 800: Cost 0.1532196604340765\n",
    "Iteration 900: Cost 0.15314221917628276\n",
    "Iteration 1000: Cost 0.15309941627408263\n",
    "Iteration 1100: Cost 0.15307518132309275\n",
    "Iteration 1200: Cost 0.153061148676072\n",
    "Iteration 1300: Cost 0.1530528417317797\n",
    "Iteration 1400: Cost 0.1530478105604014\n",
    "Iteration 1500: Cost 0.1530446884377925\n",
    "Iteration 1600: Cost 0.15304269971288165\n",
    "Iteration 1700: Cost 0.15304139700899833\n",
    "Iteration 1800: Cost 0.15304051815181116\n",
    "Iteration 1900: Cost 0.15303990698702494\n",
    "Submission file 'submission_lr0.1_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.1 and 5000 iterations.\n",
    "Iteration 0: Cost 0.6718590303808213\n",
    "Iteration 100: Cost 0.19939790632518023\n",
    "Iteration 200: Cost 0.16634833230631\n",
    "Iteration 300: Cost 0.15826074873213367\n",
    "Iteration 400: Cost 0.15540217311302632\n",
    "Iteration 500: Cost 0.15420003963383697\n",
    "Iteration 600: Cost 0.15364108111549152\n",
    "Iteration 700: Cost 0.15336371935989337\n",
    "Iteration 800: Cost 0.1532196604340765\n",
    "Iteration 900: Cost 0.15314221917628276\n",
    "Iteration 1000: Cost 0.15309941627408263\n",
    "Iteration 1100: Cost 0.15307518132309275\n",
    "Iteration 1200: Cost 0.153061148676072\n",
    "Iteration 1300: Cost 0.1530528417317797\n",
    "Iteration 1400: Cost 0.1530478105604014\n",
    "Iteration 1500: Cost 0.1530446884377925\n",
    "Iteration 1600: Cost 0.15304269971288165\n",
    "Iteration 1700: Cost 0.15304139700899833\n",
    "Iteration 1800: Cost 0.15304051815181116\n",
    "Iteration 1900: Cost 0.15303990698702494\n",
    "Iteration 2000: Cost 0.15303946891580059\n",
    "Iteration 2100: Cost 0.1530391455894283\n",
    "Iteration 2200: Cost 0.153038900321917\n",
    "Iteration 2300: Cost 0.15303870957325677\n",
    "Iteration 2400: Cost 0.153038557911915\n",
    "Iteration 2500: Cost 0.1530384349946044\n",
    "Iteration 2600: Cost 0.15303833372948267\n",
    "Iteration 2700: Cost 0.1530382491421023\n",
    "Iteration 2800: Cost 0.1530381776640243\n",
    "Iteration 2900: Cost 0.15303811667909317\n",
    "Iteration 3000: Cost 0.15303806422903277\n",
    "Iteration 3100: Cost 0.15303801881904044\n",
    "Iteration 3200: Cost 0.15303797928712823\n",
    "Iteration 3300: Cost 0.1530379447147542\n",
    "Iteration 3400: Cost 0.15303791436463385\n",
    "Iteration 3500: Cost 0.1530378876367358\n",
    "Iteration 3600: Cost 0.15303786403663563\n",
    "Iteration 3700: Cost 0.1530378431524007\n",
    "Iteration 3800: Cost 0.15303782463745222\n",
    "Iteration 3900: Cost 0.15303780819767548\n",
    "Iteration 4000: Cost 0.1530377935815909\n",
    "Iteration 4100: Cost 0.1530377805727577\n",
    "Iteration 4200: Cost 0.15303776898383126\n",
    "Iteration 4300: Cost 0.15303775865185307\n",
    "Iteration 4400: Cost 0.15303774943447754\n",
    "Iteration 4500: Cost 0.1530377412069133\n",
    "Iteration 4600: Cost 0.15303773385941974\n",
    "Iteration 4700: Cost 0.15303772729523527\n",
    "Iteration 4800: Cost 0.15303772142885097\n",
    "Iteration 4900: Cost 0.15303771618455553\n",
    "Submission file 'submission_lr0.1_iters5000.csv' created successfully.\n",
    "Training with learning rate 0.2 and 500 iterations.\n",
    "Iteration 0: Cost 0.6511135032131619\n",
    "Iteration 100: Cost 0.166035765605407\n",
    "Iteration 200: Cost 0.15535366514905263\n",
    "Iteration 300: Cost 0.1536291608325094\n",
    "Iteration 400: Cost 0.1532161319261208\n",
    "Submission file 'submission_lr0.2_iters500.csv' created successfully.\n",
    "Training with learning rate 0.2 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6511135032131619\n",
    "Iteration 100: Cost 0.166035765605407\n",
    "Iteration 200: Cost 0.15535366514905263\n",
    "Iteration 300: Cost 0.1536291608325094\n",
    "Iteration 400: Cost 0.1532161319261208\n",
    "Iteration 500: Cost 0.153098259233625\n",
    "Iteration 600: Cost 0.1530607400604881\n",
    "Iteration 700: Cost 0.1530476557147665\n",
    "Iteration 800: Cost 0.1530426361379728\n",
    "Iteration 900: Cost 0.15304048943502707\n",
    "Submission file 'submission_lr0.2_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.2 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6511135032131619\n",
    "Iteration 100: Cost 0.166035765605407\n",
    "Iteration 200: Cost 0.15535366514905263\n",
    "Iteration 300: Cost 0.1536291608325094\n",
    "Iteration 400: Cost 0.1532161319261208\n",
    "Iteration 500: Cost 0.153098259233625\n",
    "Iteration 600: Cost 0.1530607400604881\n",
    "Iteration 700: Cost 0.1530476557147665\n",
    "Iteration 800: Cost 0.1530426361379728\n",
    "Iteration 900: Cost 0.15304048943502707\n",
    "Iteration 1000: Cost 0.15303945446723707\n",
    "Iteration 1100: Cost 0.15303889221257236\n",
    "Iteration 1200: Cost 0.15303855289272353\n",
    "Iteration 1300: Cost 0.15303833036934725\n",
    "Iteration 1400: Cost 0.1530381752797822\n",
    "Iteration 1500: Cost 0.15303806246601917\n",
    "Iteration 1600: Cost 0.1530379779455873\n",
    "Iteration 1700: Cost 0.15303791332339003\n",
    "Iteration 1800: Cost 0.15303786321730997\n",
    "Iteration 1900: Cost 0.15303782398656934\n",
    "Submission file 'submission_lr0.2_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.2 and 5000 iterations.\n",
    "Iteration 0: Cost 0.6511135032131619\n",
    "Iteration 100: Cost 0.166035765605407\n",
    "Iteration 200: Cost 0.15535366514905263\n",
    "Iteration 300: Cost 0.1536291608325094\n",
    "Iteration 400: Cost 0.1532161319261208\n",
    "Iteration 500: Cost 0.153098259233625\n",
    "Iteration 600: Cost 0.1530607400604881\n",
    "Iteration 700: Cost 0.1530476557147665\n",
    "Iteration 800: Cost 0.1530426361379728\n",
    "Iteration 900: Cost 0.15304048943502707\n",
    "Iteration 1000: Cost 0.15303945446723707\n",
    "Iteration 1100: Cost 0.15303889221257236\n",
    "Iteration 1200: Cost 0.15303855289272353\n",
    "Iteration 1300: Cost 0.15303833036934725\n",
    "Iteration 1400: Cost 0.1530381752797822\n",
    "Iteration 1500: Cost 0.15303806246601917\n",
    "Iteration 1600: Cost 0.1530379779455873\n",
    "Iteration 1700: Cost 0.15303791332339003\n",
    "Iteration 1800: Cost 0.15303786321730997\n",
    "Iteration 1900: Cost 0.15303782398656934\n",
    "Iteration 2000: Cost 0.15303779306106507\n",
    "Iteration 2100: Cost 0.1530377685656072\n",
    "Iteration 2200: Cost 0.1530377490973453\n",
    "Iteration 2300: Cost 0.15303773358702857\n",
    "Iteration 2400: Cost 0.15303772120841125\n",
    "Iteration 2500: Cost 0.15303771131660412\n",
    "Iteration 2600: Cost 0.1530377034046036\n",
    "Iteration 2700: Cost 0.15303769707171264\n",
    "Iteration 2800: Cost 0.15303769200004796\n",
    "Iteration 2900: Cost 0.1530376879367304\n",
    "Iteration 3000: Cost 0.1530376846801895\n",
    "Iteration 3100: Cost 0.15303768206951748\n",
    "Iteration 3200: Cost 0.1530376799761277\n",
    "Iteration 3300: Cost 0.1530376782971788\n",
    "Iteration 3400: Cost 0.15303767695037046\n",
    "Iteration 3500: Cost 0.1530376758698088\n",
    "Iteration 3600: Cost 0.15303767500271684\n",
    "Iteration 3700: Cost 0.1530376743068109\n",
    "Iteration 3800: Cost 0.15303767374820534\n",
    "Iteration 3900: Cost 0.15303767329973958\n",
    "Iteration 4000: Cost 0.1530376729396392\n",
    "Iteration 4100: Cost 0.15303767265044496\n",
    "Iteration 4200: Cost 0.15303767241815575\n",
    "Iteration 4300: Cost 0.15303767223154144\n",
    "Iteration 4400: Cost 0.15303767208159388\n",
    "Iteration 4500: Cost 0.15303767196108595\n",
    "Iteration 4600: Cost 0.15303767186421882\n",
    "Iteration 4700: Cost 0.15303767178633884\n",
    "Iteration 4800: Cost 0.15303767172371105\n",
    "Iteration 4900: Cost 0.15303767167333726\n",
    "Submission file 'submission_lr0.2_iters5000.csv' created successfully.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f1080",
   "metadata": {},
   "source": [
    "Training with learning rate 0.0005 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6930393892742953\n",
    "Iteration 100: Cost 0.6823961893777927\n",
    "Iteration 200: Cost 0.6720175459014507\n",
    "Iteration 300: Cost 0.6618966690754329\n",
    "Iteration 400: Cost 0.6520268914414707\n",
    "Iteration 500: Cost 0.6424016711497796\n",
    "Iteration 600: Cost 0.6330145946487905\n",
    "Iteration 700: Cost 0.6238593788146457\n",
    "Iteration 800: Cost 0.6149298725653107\n",
    "Iteration 900: Cost 0.6062200580019885\n",
    "Submission file 'submission_lr0.0005_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.0005 and 1500 iterations.\n",
    "Iteration 0: Cost 0.6930393892742953\n",
    "Iteration 100: Cost 0.6823961893777927\n",
    "Iteration 200: Cost 0.6720175459014507\n",
    "Iteration 300: Cost 0.6618966690754329\n",
    "Iteration 400: Cost 0.6520268914414707\n",
    "Iteration 500: Cost 0.6424016711497796\n",
    "Iteration 600: Cost 0.6330145946487905\n",
    "Iteration 700: Cost 0.6238593788146457\n",
    "Iteration 800: Cost 0.6149298725653107\n",
    "Iteration 900: Cost 0.6062200580019885\n",
    "Iteration 1000: Cost 0.5977240511183214\n",
    "Iteration 1100: Cost 0.5894361021156319\n",
    "Iteration 1200: Cost 0.5813505953602476\n",
    "Iteration 1300: Cost 0.573462049016781\n",
    "Iteration 1400: Cost 0.5657651143891066\n",
    "Submission file 'submission_lr0.0005_iters1500.csv' created successfully.\n",
    "Training with learning rate 0.0005 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6930393892742953\n",
    "Iteration 100: Cost 0.6823961893777927\n",
    "Iteration 200: Cost 0.6720175459014507\n",
    "Iteration 300: Cost 0.6618966690754329\n",
    "Iteration 400: Cost 0.6520268914414707\n",
    "Iteration 500: Cost 0.6424016711497796\n",
    "Iteration 600: Cost 0.6330145946487905\n",
    "Iteration 700: Cost 0.6238593788146457\n",
    "Iteration 800: Cost 0.6149298725653107\n",
    "Iteration 900: Cost 0.6062200580019885\n",
    "Iteration 1000: Cost 0.5977240511183214\n",
    "Iteration 1100: Cost 0.5894361021156319\n",
    "Iteration 1200: Cost 0.5813505953602476\n",
    "Iteration 1300: Cost 0.573462049016781\n",
    "Iteration 1400: Cost 0.5657651143891066\n",
    "Iteration 1500: Cost 0.5582545749987089\n",
    "Iteration 1600: Cost 0.550925345428102\n",
    "Iteration 1700: Cost 0.543772469955078\n",
    "Iteration 1800: Cost 0.5367911210017416\n",
    "Iteration 1900: Cost 0.5299765974205239\n",
    "Submission file 'submission_lr0.0005_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.0005 and 3000 iterations.\n",
    "Iteration 0: Cost 0.6930393892742953\n",
    "Iteration 100: Cost 0.6823961893777927\n",
    "Iteration 200: Cost 0.6720175459014507\n",
    "Iteration 300: Cost 0.6618966690754329\n",
    "Iteration 400: Cost 0.6520268914414707\n",
    "Iteration 500: Cost 0.6424016711497796\n",
    "Iteration 600: Cost 0.6330145946487905\n",
    "Iteration 700: Cost 0.6238593788146457\n",
    "Iteration 800: Cost 0.6149298725653107\n",
    "Iteration 900: Cost 0.6062200580019885\n",
    "Iteration 1000: Cost 0.5977240511183214\n",
    "Iteration 1100: Cost 0.5894361021156319\n",
    "Iteration 1200: Cost 0.5813505953602476\n",
    "Iteration 1300: Cost 0.573462049016781\n",
    "Iteration 1400: Cost 0.5657651143891066\n",
    "Iteration 1500: Cost 0.5582545749987089\n",
    "Iteration 1600: Cost 0.550925345428102\n",
    "Iteration 1700: Cost 0.543772469955078\n",
    "Iteration 1800: Cost 0.5367911210017416\n",
    "Iteration 1900: Cost 0.5299765974205239\n",
    "Iteration 2000: Cost 0.5233243226377129\n",
    "Iteration 2100: Cost 0.5168298426734794\n",
    "Iteration 2200: Cost 0.5104888240558672\n",
    "Iteration 2300: Cost 0.5042970516448435\n",
    "Iteration 2400: Cost 0.49825042638116035\n",
    "Iteration 2500: Cost 0.4923449629735588\n",
    "Iteration 2600: Cost 0.48657678753667416\n",
    "Iteration 2700: Cost 0.480942135190916\n",
    "Iteration 2800: Cost 0.47543734763458173\n",
    "Iteration 2900: Cost 0.47005887069751073\n",
    "Submission file 'submission_lr0.0005_iters3000.csv' created successfully.\n",
    "Training with learning rate 0.001 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Iteration 500: Cost 0.5976348982817805\n",
    "Iteration 600: Cost 0.581264759629732\n",
    "Iteration 700: Cost 0.5656824654825797\n",
    "Iteration 800: Cost 0.5508457563266514\n",
    "Iteration 900: Cost 0.5367144682157465\n",
    "Submission file 'submission_lr0.001_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.001 and 1500 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Iteration 500: Cost 0.5976348982817805\n",
    "Iteration 600: Cost 0.581264759629732\n",
    "Iteration 700: Cost 0.5656824654825797\n",
    "Iteration 800: Cost 0.5508457563266514\n",
    "Iteration 900: Cost 0.5367144682157465\n",
    "Iteration 1000: Cost 0.5232504864065827\n",
    "Iteration 1100: Cost 0.5104176884901737\n",
    "Iteration 1200: Cost 0.49818187955519316\n",
    "Iteration 1300: Cost 0.4865107215386527\n",
    "Iteration 1400: Cost 0.4753736585809901\n",
    "Submission file 'submission_lr0.001_iters1500.csv' created successfully.\n",
    "Training with learning rate 0.001 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Iteration 500: Cost 0.5976348982817805\n",
    "Iteration 600: Cost 0.581264759629732\n",
    "Iteration 700: Cost 0.5656824654825797\n",
    "Iteration 800: Cost 0.5508457563266514\n",
    "Iteration 900: Cost 0.5367144682157465\n",
    "Iteration 1000: Cost 0.5232504864065827\n",
    "Iteration 1100: Cost 0.5104176884901737\n",
    "Iteration 1200: Cost 0.49818187955519316\n",
    "Iteration 1300: Cost 0.4865107215386527\n",
    "Iteration 1400: Cost 0.4753736585809901\n",
    "Iteration 1500: Cost 0.46474183990449436\n",
    "Iteration 1600: Cost 0.45458804147297327\n",
    "Iteration 1700: Cost 0.44488658746353194\n",
    "Iteration 1800: Cost 0.43561327238501213\n",
    "Iteration 1900: Cost 0.4267452845089753\n",
    "Submission file 'submission_lr0.001_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.001 and 3000 iterations.\n",
    "Iteration 0: Cost 0.6929316115631402\n",
    "Iteration 100: Cost 0.671913770424609\n",
    "Iteration 200: Cost 0.651926978625397\n",
    "Iteration 300: Cost 0.6329184054989727\n",
    "Iteration 400: Cost 0.6148372694197922\n",
    "Iteration 500: Cost 0.5976348982817805\n",
    "Iteration 600: Cost 0.581264759629732\n",
    "Iteration 700: Cost 0.5656824654825797\n",
    "Iteration 800: Cost 0.5508457563266514\n",
    "Iteration 900: Cost 0.5367144682157465\n",
    "Iteration 1000: Cost 0.5232504864065827\n",
    "Iteration 1100: Cost 0.5104176884901737\n",
    "Iteration 1200: Cost 0.49818187955519316\n",
    "Iteration 1300: Cost 0.4865107215386527\n",
    "Iteration 1400: Cost 0.4753736585809901\n",
    "Iteration 1500: Cost 0.46474183990449436\n",
    "Iteration 1600: Cost 0.45458804147297327\n",
    "Iteration 1700: Cost 0.44488658746353194\n",
    "Iteration 1800: Cost 0.43561327238501213\n",
    "Iteration 1900: Cost 0.4267452845089753\n",
    "Iteration 2000: Cost 0.4182611311349761\n",
    "Iteration 2100: Cost 0.4101405660895851\n",
    "Iteration 2200: Cost 0.40236451975546805\n",
    "Iteration 2300: Cost 0.394915031840482\n",
    "Iteration 2400: Cost 0.38777518702502334\n",
    "Iteration 2500: Cost 0.3809290535667834\n",
    "Iteration 2600: Cost 0.3743616248939087\n",
    "Iteration 2700: Cost 0.36805876417871625\n",
    "Iteration 2800: Cost 0.3620071518532497\n",
    "Iteration 2900: Cost 0.35619423600380706\n",
    "Submission file 'submission_lr0.001_iters3000.csv' created successfully.\n",
    "Training with learning rate 0.005 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6920698785555588\n",
    "Iteration 100: Cost 0.5969221153190414\n",
    "Iteration 200: Cost 0.5226601808873914\n",
    "Iteration 300: Cost 0.46425087427692613\n",
    "Iteration 400: Cost 0.4178503070652221\n",
    "Iteration 500: Cost 0.380582881980962\n",
    "Iteration 600: Cost 0.3503143465226343\n",
    "Iteration 700: Cost 0.3254606937995367\n",
    "Iteration 800: Cost 0.3048405992035328\n",
    "Iteration 900: Cost 0.28756623963290223\n",
    "Submission file 'submission_lr0.005_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.005 and 1500 iterations.\n",
    "Iteration 0: Cost 0.6920698785555588\n",
    "Iteration 100: Cost 0.5969221153190414\n",
    "Iteration 200: Cost 0.5226601808873914\n",
    "Iteration 300: Cost 0.46425087427692613\n",
    "Iteration 400: Cost 0.4178503070652221\n",
    "Iteration 500: Cost 0.380582881980962\n",
    "Iteration 600: Cost 0.3503143465226343\n",
    "Iteration 700: Cost 0.3254606937995367\n",
    "Iteration 800: Cost 0.3048405992035328\n",
    "Iteration 900: Cost 0.28756623963290223\n",
    "Iteration 1000: Cost 0.27296415670758495\n",
    "Iteration 1100: Cost 0.26051835838714615\n",
    "Iteration 1200: Cost 0.24982943764105256\n",
    "Iteration 1300: Cost 0.2405850882835434\n",
    "Iteration 1400: Cost 0.2325387032910246\n",
    "Submission file 'submission_lr0.005_iters1500.csv' created successfully.\n",
    "Training with learning rate 0.005 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6920698785555588\n",
    "Iteration 100: Cost 0.5969221153190414\n",
    "Iteration 200: Cost 0.5226601808873914\n",
    "Iteration 300: Cost 0.46425087427692613\n",
    "Iteration 400: Cost 0.4178503070652221\n",
    "Iteration 500: Cost 0.380582881980962\n",
    "Iteration 600: Cost 0.3503143465226343\n",
    "Iteration 700: Cost 0.3254606937995367\n",
    "Iteration 800: Cost 0.3048405992035328\n",
    "Iteration 900: Cost 0.28756623963290223\n",
    "Iteration 1000: Cost 0.27296415670758495\n",
    "Iteration 1100: Cost 0.26051835838714615\n",
    "Iteration 1200: Cost 0.24982943764105256\n",
    "Iteration 1300: Cost 0.2405850882835434\n",
    "Iteration 1400: Cost 0.2325387032910246\n",
    "Iteration 1500: Cost 0.22549371554371603\n",
    "Iteration 1600: Cost 0.21929203890486432\n",
    "Iteration 1700: Cost 0.2138054573724416\n",
    "Iteration 1800: Cost 0.20892915083106223\n",
    "Iteration 1900: Cost 0.20457678259698484\n",
    "Submission file 'submission_lr0.005_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.005 and 3000 iterations.\n",
    "Iteration 0: Cost 0.6920698785555588\n",
    "Iteration 100: Cost 0.5969221153190414\n",
    "Iteration 200: Cost 0.5226601808873914\n",
    "Iteration 300: Cost 0.46425087427692613\n",
    "Iteration 400: Cost 0.4178503070652221\n",
    "Iteration 500: Cost 0.380582881980962\n",
    "Iteration 600: Cost 0.3503143465226343\n",
    "Iteration 700: Cost 0.3254606937995367\n",
    "Iteration 800: Cost 0.3048405992035328\n",
    "Iteration 900: Cost 0.28756623963290223\n",
    "Iteration 1000: Cost 0.27296415670758495\n",
    "Iteration 1100: Cost 0.26051835838714615\n",
    "Iteration 1200: Cost 0.24982943764105256\n",
    "Iteration 1300: Cost 0.2405850882835434\n",
    "Iteration 1400: Cost 0.2325387032910246\n",
    "Iteration 1500: Cost 0.22549371554371603\n",
    "Iteration 1600: Cost 0.21929203890486432\n",
    "Iteration 1700: Cost 0.2138054573724416\n",
    "Iteration 1800: Cost 0.20892915083106223\n",
    "Iteration 1900: Cost 0.20457678259698484\n",
    "Iteration 2000: Cost 0.20067673867027933\n",
    "Iteration 2100: Cost 0.19716922380319563\n",
    "Iteration 2200: Cost 0.19400400056391706\n",
    "Iteration 2300: Cost 0.19113861504426816\n",
    "Iteration 2400: Cost 0.188536993917016\n",
    "Iteration 2500: Cost 0.18616832711661543\n",
    "Iteration 2600: Cost 0.18400617188461968\n",
    "Iteration 2700: Cost 0.18202772963285307\n",
    "Iteration 2800: Cost 0.18021325866826993\n",
    "Iteration 2900: Cost 0.1785455944404969\n",
    "Submission file 'submission_lr0.005_iters3000.csv' created successfully.\n",
    "Training with learning rate 0.01 and 1000 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Iteration 500: Cost 0.2727598500850447\n",
    "Iteration 600: Cost 0.24967118426110524\n",
    "Iteration 700: Cost 0.23241358944020898\n",
    "Iteration 800: Cost 0.21919137245317338\n",
    "Iteration 900: Cost 0.20884692215052364\n",
    "Submission file 'submission_lr0.01_iters1000.csv' created successfully.\n",
    "Training with learning rate 0.01 and 1500 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Iteration 500: Cost 0.2727598500850447\n",
    "Iteration 600: Cost 0.24967118426110524\n",
    "Iteration 700: Cost 0.23241358944020898\n",
    "Iteration 800: Cost 0.21919137245317338\n",
    "Iteration 900: Cost 0.20884692215052364\n",
    "Iteration 1000: Cost 0.2006086886554709\n",
    "Iteration 1100: Cost 0.19394704232013651\n",
    "Iteration 1200: Cost 0.1884888446543932\n",
    "Iteration 1300: Cost 0.1839651127455822\n",
    "Iteration 1400: Cost 0.1801779743360883\n",
    "Submission file 'submission_lr0.01_iters1500.csv' created successfully.\n",
    "Training with learning rate 0.01 and 2000 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Iteration 500: Cost 0.2727598500850447\n",
    "Iteration 600: Cost 0.24967118426110524\n",
    "Iteration 700: Cost 0.23241358944020898\n",
    "Iteration 800: Cost 0.21919137245317338\n",
    "Iteration 900: Cost 0.20884692215052364\n",
    "Iteration 1000: Cost 0.2006086886554709\n",
    "Iteration 1100: Cost 0.19394704232013651\n",
    "Iteration 1200: Cost 0.1884888446543932\n",
    "Iteration 1300: Cost 0.1839651127455822\n",
    "Iteration 1400: Cost 0.1801779743360883\n",
    "Iteration 1500: Cost 0.1769792246792327\n",
    "Iteration 1600: Cost 0.17425606399497567\n",
    "Iteration 1700: Cost 0.17192139702218776\n",
    "Iteration 1800: Cost 0.1699071009490414\n",
    "Iteration 1900: Cost 0.16815926713067314\n",
    "Submission file 'submission_lr0.01_iters2000.csv' created successfully.\n",
    "Training with learning rate 0.01 and 3000 iterations.\n",
    "Iteration 0: Cost 0.6909939339984333\n",
    "Iteration 100: Cost 0.5219232594570349\n",
    "Iteration 200: Cost 0.41733747940939536\n",
    "Iteration 300: Cost 0.3499475526044885\n",
    "Iteration 400: Cost 0.3045705124876015\n",
    "Iteration 500: Cost 0.2727598500850447\n",
    "Iteration 600: Cost 0.24967118426110524\n",
    "Iteration 700: Cost 0.23241358944020898\n",
    "Iteration 800: Cost 0.21919137245317338\n",
    "Iteration 900: Cost 0.20884692215052364\n",
    "Iteration 1000: Cost 0.2006086886554709\n",
    "Iteration 1100: Cost 0.19394704232013651\n",
    "Iteration 1200: Cost 0.1884888446543932\n",
    "Iteration 1300: Cost 0.1839651127455822\n",
    "Iteration 1400: Cost 0.1801779743360883\n",
    "Iteration 1500: Cost 0.1769792246792327\n",
    "Iteration 1600: Cost 0.17425606399497567\n",
    "Iteration 1700: Cost 0.17192139702218776\n",
    "Iteration 1800: Cost 0.1699071009490414\n",
    "Iteration 1900: Cost 0.16815926713067314\n",
    "Iteration 2000: Cost 0.16663478148771985\n",
    "Iteration 2100: Cost 0.1652988294055676\n",
    "Iteration 2200: Cost 0.1641230497604212\n",
    "Iteration 2300: Cost 0.16308415170418578\n",
    "Iteration 2400: Cost 0.162162865996327\n",
    "Iteration 2500: Cost 0.16134314133637262\n",
    "Iteration 2600: Cost 0.16061152227497558\n",
    "Iteration 2700: Cost 0.15995666319789137\n",
    "Iteration 2800: Cost 0.15936894533645832\n",
    "Iteration 2900: Cost 0.1588401725352023\n",
    "Submission file 'submission_lr0.01_iters3000.csv' created successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
